{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "from MatrixVectorizer import *\n",
    "import torch\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import seaborn as sns\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Check for CUDA (GPU support) and set device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # For multi-GPU setups\n",
    "    # Additional settings for ensuring reproducibility on CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_size = 160\n",
    "HR_size = 268"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antivectorize_df(adj_mtx_df, size):\n",
    "    \n",
    "    num_subject = adj_mtx_df.shape[0]\n",
    "    adj_mtx = np.zeros((num_subject, size, size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "    for i in range(num_subject):\n",
    "        adj_mtx[i] = MatrixVectorizer.anti_vectorize(adj_mtx_df.iloc[i], size) # torch.from_numpy(MatrixVectorizer.anti_vectorize(A_LR_train.iloc[i], LR_size))\n",
    "    return adj_mtx\n",
    "\n",
    "\n",
    "# A_LR_train = pd.read_csv(\"../data/lr_train.csv\")\n",
    "# A_HR_train = pd.read_csv(\"../data/hr_train.csv\")\n",
    "# A_LR_test = pd.read_csv(\"../data/lr_test.csv\")\n",
    "\n",
    "# np.save('A_LR_train_matrix.npy', antivectorize_df(A_LR_train, LR_size))\n",
    "# np.save('A_HR_train_matrix.npy', antivectorize_df(A_HR_train, HR_size))\n",
    "# np.save('A_LR_test_matrix.npy', antivectorize_df(A_LR_test, LR_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 160, 160)\n",
      "(167, 268, 268)\n",
      "(112, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "A_LR_train_matrix = np.load('A_LR_train_matrix.npy')\n",
    "A_HR_train_matrix = np.load('A_HR_train_matrix.npy')\n",
    "A_LR_test_matrix = np.load(\"A_LR_test_matrix.npy\")\n",
    "\n",
    "print(A_LR_train_matrix.shape)\n",
    "print(A_HR_train_matrix.shape)\n",
    "print(A_LR_test_matrix.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=200, lr=0.0001, splits=3, lmbda=20, lr_dim=160, hr_dim=268, hidden_dim=280, hidden_gat_dim=268, padding=26, embedding_size=32, early_stop_patient=5, dropout_rate=0.2, p_perturbe=0.5, p_drop_node=0.03, p_drop_edges=0.1, mean_dense=0.0, std_dense=0.01, mean_gaussian=0.0, std_gaussian=0.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "from train import *\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "lmbda = 20 # 16\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GSR-Net')\n",
    "parser.add_argument('--epochs', type=int, default=epochs, metavar='no_epochs',\n",
    "                help='number of episode to train ')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, metavar='lr',\n",
    "                help='learning rate (default: 0.0001 using Adam Optimizer)')\n",
    "parser.add_argument('--splits', type=int, default=3, metavar='n_splits',\n",
    "                help='no of cross validation folds')\n",
    "parser.add_argument('--lmbda', type=int, default=lmbda, metavar='L',\n",
    "                help='self-reconstruction error hyperparameter')\n",
    "parser.add_argument('--lr_dim', type=int, default=LR_size, metavar='N',\n",
    "                help='adjacency matrix input dimensions')\n",
    "parser.add_argument('--hr_dim', type=int, default=HR_size, metavar='N',\n",
    "                help='super-resolved adjacency matrix output dimensions')\n",
    "parser.add_argument('--hidden_dim', type=int, default=280, metavar='N',\n",
    "                help='hidden GraphConvolutional layer dimensions')\n",
    "parser.add_argument('--hidden_gat_dim', type=int, default=268, metavar='hidden_gat_dim',\n",
    "                help='hidden GAT layer dimensions')\n",
    "parser.add_argument('--padding', type=int, default=26, metavar='padding',\n",
    "                help='dimensions of padding')\n",
    "# parser.add_argument('--padding', type=int, default=26, metavar='padding',\n",
    "#                 help='dimensions of padding')\n",
    "parser.add_argument('--embedding_size', type=int, default=32, metavar='embedding_size',\n",
    "                help='node embedding size')\n",
    "parser.add_argument('--early_stop_patient', type=int, default=5, metavar='early_stop_patient',\n",
    "                help='early_stop_patience')\n",
    "parser.add_argument('--dropout_rate', type=float, default=0.2, metavar='dropout_rate',\n",
    "                help='dropout_rate')\n",
    "parser.add_argument('--p_perturbe', type=float, default=0.5, metavar='p_perturbe',\n",
    "                help='p_perturbe')\n",
    "parser.add_argument('--p_drop_node', type=float, default=0.03, metavar='p_drop_node',\n",
    "                help='p_drop_node')\n",
    "parser.add_argument('--p_drop_edges', type=float, default=0.1, metavar='p_drop_edges',\n",
    "                help='p_drop_edges')\n",
    "\n",
    "parser.add_argument('--mean_dense', type=float, default=0., metavar='mean',\n",
    "                        help='mean of the normal distribution in Dense Layer')\n",
    "parser.add_argument('--std_dense', type=float, default=0.01, metavar='std',\n",
    "                    help='standard deviation of the normal distribution in Dense Layer')\n",
    "parser.add_argument('--mean_gaussian', type=float, default=0., metavar='mean',\n",
    "                    help='mean of the normal distribution in Gaussian Noise Layer')\n",
    "parser.add_argument('--std_gaussian', type=float, default=0.1, metavar='std',\n",
    "                    help='standard deviation of the normal distribution in Gaussian Noise Layer')\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty Namespace to hold the default arguments\n",
    "args = parser.parse_args([]) \n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 160, 160)\n",
      "(167, 268, 268)\n"
     ]
    }
   ],
   "source": [
    "# SIMULATING THE DATA: EDIT TO ENTER YOUR OWN DATA\n",
    "X = A_LR_train_matrix #np.random.normal(0, 0.5, (167, 160, 160))\n",
    "Y = A_HR_train_matrix #np.random.normal(0, 0.5, (167, 288, 288))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_degree_matrix_normalization_batch_numpy(adjacency_batch):\n",
    "    \"\"\"\n",
    "    Optimizes the degree matrix normalization for a batch of adjacency matrices using NumPy.\n",
    "    Computes the normalized adjacency matrix D^-1 * A for each graph in the batch.\n",
    "    \n",
    "    Parameters:\n",
    "    - adjacency_batch: A NumPy array of shape (batch_size, num_nodes, num_nodes) representing\n",
    "                       a batch of adjacency matrices.\n",
    "\n",
    "    Returns:\n",
    "    - A NumPy array of normalized adjacency matrices.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    # Calculate the degree for each node in the batch\n",
    "    adjacency_batch = adjacency_batch + 2*np.eye(adjacency_batch.shape[1])\n",
    "    d = adjacency_batch.sum(axis=2) + epsilon\n",
    "    \n",
    "    # Compute the inverse degree matrix D^-1 for the batch\n",
    "    D_inv = np.reciprocal(d)[:, :, np.newaxis] * np.eye(adjacency_batch.shape[1])[np.newaxis, :, :]\n",
    "    \n",
    "    # Normalize the adjacency matrix using batch matrix multiplication\n",
    "    normalized_adjacency_batch = np.matmul(D_inv, adjacency_batch)\n",
    "    \n",
    "    return normalized_adjacency_batch\n",
    "\n",
    "def symmetric_norm(A):\n",
    "    num_samples = A.shape[0]  # Number of samples, i.e., slices in the 3D tensor\n",
    "\n",
    "    # Initialize an empty array for the normalized matrices\n",
    "    A_normalized = np.zeros_like(A)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Extract the i-th adjacency matrix\n",
    "        Ai = A[i, :, :]\n",
    "        \n",
    "        # Compute the degree matrix D and its inverse square root for Ai\n",
    "        Di = np.diag(np.sum(Ai, axis=1))\n",
    "        D_inv_sqrt_i = np.linalg.inv(np.sqrt(Di))\n",
    "        \n",
    "        # Normalize the adjacency matrix\n",
    "        A_normalized[i, :, :] = D_inv_sqrt_i @ Ai @ D_inv_sqrt_i\n",
    "    return A_normalized\n",
    "\n",
    "def compute_pagerank_normalization(adjacency_matrices):\n",
    "    \"\"\"\n",
    "    Normalizes each adjacency matrix in a batch using PageRank centrality values.\n",
    "    \n",
    "    Parameters:\n",
    "    - adjacency_matrices: A NumPy array with shape (n_samples, n_dim, n_dim) representing the adjacency matrices.\n",
    "    \n",
    "    Returns:\n",
    "    - A NumPy array of the same shape, with each adjacency matrix normalized.\n",
    "    \"\"\"\n",
    "    n_samples, n_dim, _ = adjacency_matrices.shape\n",
    "    normalized_matrices = np.zeros_like(adjacency_matrices)\n",
    "    \n",
    "    for i in tqdm(range(n_samples)):\n",
    "        adjacency = adjacency_matrices[i]\n",
    "        \n",
    "        # Convert adjacency matrix to graph\n",
    "        G = nx.from_numpy_array(adjacency, create_using=nx.DiGraph)\n",
    "        \n",
    "        # Compute PageRank\n",
    "        pr_dict = nx.pagerank(G, alpha=0.85, max_iter=100, tol=1e-6)\n",
    "        \n",
    "        # Create a diagonal matrix with PageRank values\n",
    "        pr_values = np.array([pr_dict[node] for node in range(n_dim)])\n",
    "        pr_diag = np.diag(pr_values)\n",
    "        \n",
    "        # Normalize the adjacency matrix using the PageRank diagonal matrix\n",
    "        normalized_adjacency = np.dot(pr_diag, adjacency)\n",
    "        \n",
    "        normalized_matrices[i] = normalized_adjacency\n",
    "    \n",
    "    return normalized_matrices\n",
    "    \n",
    "\n",
    "# X = compute_pagerank_normalization(X)\n",
    "# A_LR_test_matrix = compute_pagerank_normalization(A_LR_test_matrix)\n",
    "\n",
    "X = compute_degree_matrix_normalization_batch_numpy(X)\n",
    "A_LR_test_matrix = compute_degree_matrix_normalization_batch_numpy(A_LR_test_matrix)\n",
    "\n",
    "# X = symmetric_norm(X)\n",
    "# A_LR_test_matrix = symmetric_norm(A_LR_test_matrix)\n",
    "\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-06 15:17:31,298] A new study created in memory with name: GSR_hyperparameter_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: {'lr': 0.00014005663314080547, 'lmbda': 27, 'hidden_dim': 500, 'patience': 13, 'dropout_rate': 0.40925991846405374, 'p_perturbe': 0.0, 'p_drop_node': 0.019031569584973363, 'p_drop_edges': 0.08722156242389797}\n",
      "----- Fold 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 100%|██████████| 1/1 [00:11<00:00, 11.82s/epoch, test_error=0.181, train_error=0.223, train_loss=1.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 100%|██████████| 1/1 [00:11<00:00, 11.73s/epoch, test_error=0.19, train_error=0.221, train_loss=1.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 3 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 100%|██████████| 1/1 [00:11<00:00, 11.80s/epoch, test_error=0.186, train_error=0.221, train_loss=1.88]\n",
      "[I 2024-03-06 15:18:16,811] Trial 0 finished with value: 0.1856362436918211 and parameters: {'lr': 0.00014005663314080547, 'lmbda': 27, 'hidden_dim': 500, 'patience': 13, 'dropout_rate': 0.40925991846405374, 'p_perturbe': 0.0, 'p_drop_node': 0.019031569584973363, 'p_drop_edges': 0.08722156242389797}. Best is trial 0 with value: 0.1856362436918211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best MAE: 0.186061046611179 with params: {'lr': 0.00014005663314080547, 'lmbda': 27, 'hidden_dim': 500, 'patience': 13, 'dropout_rate': 0.40925991846405374, 'p_perturbe': 0.0, 'p_drop_node': 0.019031569584973363, 'p_drop_edges': 0.08722156242389797}\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "best_mae = 1000\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "def hyperparameter_search(n_trials=40):\n",
    "    def objective(trial):\n",
    "        global best_mae\n",
    "        global best_params\n",
    "        global best_model\n",
    "        ks = [0.8, 0.5]\n",
    "        num_epochs = 200\n",
    "        lr = trial.suggest_float('lr', 1e-6, 1e-2, log=True)\n",
    "        lmbda = trial.suggest_int('lmbda', 1, 50)\n",
    "        hidden_dim = trial.suggest_categorical('hidden_dim', [100, 200, 300, 400, 500])\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.7, log=True)\n",
    "        p_perturbe = trial.suggest_float('p_perturbe', 0, 0.7, step=0.1)\n",
    "        p_drop_node = trial.suggest_float('p_drop_node', 0.01, 0.2, log=True)\n",
    "        p_drop_edges = trial.suggest_float('p_drop_edges', 0.05, 0.2, log=True)\n",
    "\n",
    "\n",
    "        args.epochs = num_epochs\n",
    "        args.lr = lr\n",
    "        args.lmbda = lmbda\n",
    "        args.hidden_dim = hidden_dim\n",
    "        args.early_stop_patient = patience\n",
    "        args.dropout_rate = dropout_rate\n",
    "        args.p_perturbe = p_perturbe\n",
    "        args.p_drop_node = p_drop_node\n",
    "        args.p_drop_edges = p_drop_edges\n",
    "\n",
    "        params = {\n",
    "                \"lr\": lr,\n",
    "                \"lmbda\": lmbda,\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"patience\": patience,\n",
    "                \"dropout_rate\": dropout_rate,\n",
    "                \"p_perturbe\": p_perturbe,\n",
    "                \"p_drop_node\": p_drop_node,\n",
    "                \"p_drop_edges\": p_drop_edges,\n",
    "            }\n",
    "        print(f\"Trial {trial.number}: {params}\")\n",
    "\n",
    "        cv = KFold(n_splits=args.splits, random_state=random_seed, shuffle=True)\n",
    "\n",
    "        mae_list = []\n",
    "        i = 1\n",
    "        for train_index, test_index in cv.split(X):\n",
    "            print(f\"----- Fold {i} -----\")\n",
    "            subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = X[\n",
    "                train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "\n",
    "            modelG = GSRNet(ks, args).to(device)\n",
    "            optimizerG = torch.optim.Adam(modelG.parameters(), lr=args.lr)\n",
    "\n",
    "            modelD = Discriminator(args).to(device)\n",
    "            optimizerD = optim.Adam(modelD.parameters(), lr=args.lr)\n",
    "\n",
    "            return_model = train_gan(modelG, optimizerG, modelD, optimizerD, subjects_adj, subjects_ground_truth, args, test_adj, test_ground_truth)\n",
    "            test_mae = test(return_model, test_adj, test_ground_truth, args)\n",
    "            mae_list.append(test_mae)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        mean_mae = np.mean(mae_list)\n",
    "        if mean_mae < best_mae:\n",
    "            best_mae = mean_mae\n",
    "            best_params = params\n",
    "            best_model = return_model\n",
    "            print(f\"New best MAE: {test_mae} with params: {best_params}\")\n",
    "\n",
    "        return mean_mae\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize', study_name='GSR_hyperparameter_search', sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study.best_params\n",
    "\n",
    "best_params = hyperparameter_search(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   0%|          | 0/200 [00:00<?, ?epoch/s]/Users/carlosbrat/Library/Mobile Documents/com~apple~CloudDocs/Imperial/Term2/Deep Graph-based Learning/CW2/graph_super_resolution/gsr_net/layers.py:35: UserWarning: The operator 'aten::_linalg_eigh.eigenvalues' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  eig_val_lr, U_lr = torch.linalg.eigh(lr, UPLO='U')\n",
      "Epoch Progress:   3%|▎         | 6/200 [01:10<38:07, 11.79s/epoch, test_error=0.171, train_error=0.174, train_loss=3.42]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m netD \u001b[38;5;241m=\u001b[39m Discriminator(args)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m optimizerD \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(netD\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlr)\n\u001b[0;32m---> 23\u001b[0m return_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizerG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizerD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubjects_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubjects_ground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_adj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_ground_truth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ground_truth\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# return_model = train(netG, optimizerG, subjects_adj, subjects_ground_truth, args, test_adj, test_ground_truth)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m test_mae \u001b[38;5;241m=\u001b[39m test(return_model, test_adj, test_ground_truth, args)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Imperial/Term2/Deep Graph-based Learning/CW2/graph_super_resolution/gsr_net/train.py:296\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m(netG, optimizerG, netD, optimizerD, subjects_adj, subjects_labels, args, test_adj, test_ground_truth)\u001b[0m\n\u001b[1;32m    293\u001b[0m hr \u001b[38;5;241m=\u001b[39m hr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    294\u001b[0m net_outs \u001b[38;5;241m=\u001b[39m net_outs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 296\u001b[0m padded_hr \u001b[38;5;241m=\u001b[39m \u001b[43mpad_HR_adj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m padded_hr \u001b[38;5;241m=\u001b[39m padded_hr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    298\u001b[0m _, U_hr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(padded_hr, UPLO\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Imperial/Term2/Deep Graph-based Learning/CW2/graph_super_resolution/gsr_net/preprocessing.py:34\u001b[0m, in \u001b[0;36mpad_HR_adj\u001b[0;34m(label, split)\u001b[0m\n\u001b[1;32m     31\u001b[0m label_padded \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(label, padding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create an identity matrix of the same size as the padded tensor\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m identity \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_padded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Add the identity matrix to the padded tensor to set diagonal elements to 1\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Assuming the operation intended is to ensure diagonal elements are set to 1 post padding\u001b[39;00m\n\u001b[1;32m     38\u001b[0m label_padded \u001b[38;5;241m=\u001b[39m label_padded \u001b[38;5;241m+\u001b[39m identity\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=args.splits, random_state=random_seed, shuffle=True)\n",
    "\n",
    "ks = [0.8, 0.5]\n",
    "\n",
    "best_model_fold_list = []\n",
    "data_fold_list = []\n",
    "i = 1\n",
    "for train_index, test_index in cv.split(X):\n",
    "\n",
    "    print(f\"----- Fold {i} -----\")\n",
    "\n",
    "    subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = X[\n",
    "        train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "    data_fold_list.append((subjects_adj, test_adj, subjects_ground_truth, test_ground_truth))\n",
    "\n",
    "\n",
    "    netG = GSRNet(ks, args).to(device)\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=args.lr)\n",
    "\n",
    "    netD = Discriminator(args).to(device)\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=args.lr)\n",
    "\n",
    "    return_model = train_gan(\n",
    "        netG, \n",
    "        optimizerG, \n",
    "        netD,\n",
    "        optimizerD,\n",
    "        subjects_adj, \n",
    "        subjects_ground_truth, \n",
    "        args, \n",
    "        test_adj=test_adj, \n",
    "        test_ground_truth=test_ground_truth\n",
    "    )\n",
    "\n",
    "    # return_model = train(netG, optimizerG, subjects_adj, subjects_ground_truth, args, test_adj, test_ground_truth)\n",
    "    test_mae = test(return_model, test_adj, test_ground_truth, args)\n",
    "    print(f\"Val MAE: {test_mae}\")\n",
    "    best_model_fold_list.append(return_model)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "def evaluate(pred_matrices, gt_matrices, cal_graph=False):\n",
    "\n",
    "    # pred_matrices = pred_matrices.cpu().detach().numpy()\n",
    "    # gt_matrices = gt_matrices.cpu().detach().numpy()\n",
    "\n",
    "    num_test_samples = gt_matrices.shape[0]\n",
    "\n",
    "    # Initialize lists to store MAEs for each centrality measure\n",
    "    mae_bc = []\n",
    "    mae_ec = []\n",
    "    mae_pc = []\n",
    "    \n",
    "    pred_1d = []\n",
    "    gt_1d = []\n",
    "\n",
    "    # Iterate over each test sample\n",
    "    for i in tqdm(range(num_test_samples)):\n",
    "\n",
    "        pred_1d.append(MatrixVectorizer.vectorize(pred_matrices[i]))\n",
    "        gt_1d.append(MatrixVectorizer.vectorize(gt_matrices[i]))\n",
    "\n",
    "        if cal_graph:\n",
    "            # Convert adjacency matrices to NetworkX graphs\n",
    "            pred_graph = nx.from_numpy_array(pred_matrices[i])\n",
    "            gt_graph = nx.from_numpy_array(gt_matrices[i])\n",
    "\n",
    "            # Compute centrality measures\n",
    "            pred_bc = nx.betweenness_centrality(pred_graph, weight=\"weight\")\n",
    "            pred_ec = nx.eigenvector_centrality(pred_graph, weight=\"weight\")\n",
    "            pred_pc = nx.pagerank(pred_graph, weight=\"weight\")\n",
    "\n",
    "            gt_bc = nx.betweenness_centrality(gt_graph, weight=\"weight\")\n",
    "            gt_ec = nx.eigenvector_centrality(gt_graph, weight=\"weight\")\n",
    "            gt_pc = nx.pagerank(gt_graph, weight=\"weight\")\n",
    "\n",
    "            # Convert centrality dictionaries to lists\n",
    "            pred_bc_values = list(pred_bc.values())\n",
    "            pred_ec_values = list(pred_ec.values())\n",
    "            pred_pc_values = list(pred_pc.values())\n",
    "\n",
    "            gt_bc_values = list(gt_bc.values())\n",
    "            gt_ec_values = list(gt_ec.values())\n",
    "            gt_pc_values = list(gt_pc.values())\n",
    "\n",
    "            # Compute MAEs\n",
    "            mae_bc.append(mean_absolute_error(pred_bc_values, gt_bc_values))\n",
    "            mae_ec.append(mean_absolute_error(pred_ec_values, gt_ec_values))\n",
    "            mae_pc.append(mean_absolute_error(pred_pc_values, gt_pc_values))\n",
    "\n",
    "    if cal_graph:\n",
    "        # Compute average MAEs\n",
    "        avg_mae_bc = sum(mae_bc) / len(mae_bc)\n",
    "        avg_mae_ec = sum(mae_ec) / len(mae_ec)\n",
    "        avg_mae_pc = sum(mae_pc) / len(mae_pc)\n",
    "\n",
    "    # vectorize and flatten\n",
    "    pred_1d = np.concatenate(pred_1d, axis=0).flatten()\n",
    "    gt_1d = np.concatenate(gt_1d, axis=0).flatten()\n",
    "\n",
    "    mae = mean_absolute_error(pred_1d, gt_1d)\n",
    "    pcc = pearsonr(pred_1d, gt_1d)[0]\n",
    "    js_dis = jensenshannon(pred_1d, gt_1d)\n",
    "\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"PCC: \", pcc)\n",
    "    print(\"Jensen-Shannon Distance: \", js_dis)\n",
    "    if cal_graph:\n",
    "        print(\"Average MAE betweenness centrality:\", avg_mae_bc)\n",
    "        print(\"Average MAE eigenvector centrality:\", avg_mae_ec)\n",
    "        print(\"Average MAE PageRank centrality:\", avg_mae_pc)\n",
    "\n",
    "    if cal_graph:\n",
    "\n",
    "        res = {\n",
    "            \"MAE\": mae,\n",
    "            \"PCC\": pcc,\n",
    "            \"JSD\": js_dis,\n",
    "            \"MAE_(BC)\": avg_mae_bc,\n",
    "            \"MAE_(EC)\": avg_mae_ec,\n",
    "            \"MAE_(PC)\": avg_mae_pc\n",
    "        }\n",
    "    else:\n",
    "        res = {\n",
    "            \"MAE\": mae,\n",
    "            \"PCC\": pcc,\n",
    "            \"JSD\": js_dis,\n",
    "            # \"MAE_(BC)\": avg_mae_bc,\n",
    "            # \"MAE_(EC)\": avg_mae_ec,\n",
    "            # \"MAE_(PC)\": avg_mae_pc\n",
    "        }\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 75.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.1331318125532413\n",
      "PCC:  0.6382396563770187\n",
      "Jensen-Shannon Distance:  0.2843298892608118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 77.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.14506266190815634\n",
      "PCC:  0.5938296665594252\n",
      "Jensen-Shannon Distance:  0.30119436667206106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 94.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.139692404669245\n",
      "PCC:  0.6129086784725483\n",
      "Jensen-Shannon Distance:  0.29030578028209403\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>PCC</th>\n",
       "      <th>JSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133132</td>\n",
       "      <td>0.638240</td>\n",
       "      <td>0.284330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145063</td>\n",
       "      <td>0.593830</td>\n",
       "      <td>0.301194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139692</td>\n",
       "      <td>0.612909</td>\n",
       "      <td>0.290306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE       PCC       JSD\n",
       "0  0.133132  0.638240  0.284330\n",
       "1  0.145063  0.593830  0.301194\n",
       "2  0.139692  0.612909  0.290306"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list = []\n",
    "\n",
    "for i in range(args.splits):\n",
    "    _, test_adjs, _, gt_matrices = data_fold_list[i]\n",
    "    model = best_model_fold_list[i]\n",
    "    model.eval()\n",
    "    pred_matrices = np.zeros(gt_matrices.shape)\n",
    "    with torch.no_grad():\n",
    "        for j, test_adj in enumerate(test_adjs):\n",
    "            pred_matrices[j], _, _, _ = model(torch.from_numpy(test_adj))\n",
    "    res_list.append(evaluate(pred_matrices, gt_matrices, cal_graph=False))\n",
    "\n",
    "pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_list = []\n",
    "\n",
    "# for i in range(args.splits):\n",
    "#     _, test_adjs, _, gt_matrices = data_fold_list[i]\n",
    "#     model = best_model_fold_list[i]\n",
    "#     model.eval()\n",
    "#     pred_matrices = np.zeros(gt_matrices.shape)\n",
    "#     with torch.no_grad():\n",
    "#         for j, test_adj in enumerate(test_adjs):\n",
    "#             pred_matrices[j], _, _, _ = model(torch.from_numpy(test_adj))\n",
    "#     res_list.append(evaluate(pred_matrices, gt_matrices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_metrics_fold(res_list):\n",
    "    df = pd.DataFrame(res_list)\n",
    "    df = df.rename(columns={\"mae\": \"MAE\", \"pcc\": \"PCC\", \"js_dis\": \"JSD\", \"avg_mae_bc\": \"MAE_(BC)\", \"avg_mae_ec\": \"MAE_(EC)\", \"avg_mae_pc\": \"MAE_(PC)\"})\n",
    "    df.index = df.index.set_names(['Fold'])\n",
    "    df.loc['mean'] = df.mean()\n",
    "    avg_data = df.iloc[-1, :]\n",
    "    df.loc['std'] = df.std()\n",
    "    errors = df.iloc[-1, :].tolist()\n",
    "    df = df.reset_index()\n",
    "    df = df.iloc[:-2, :]\n",
    "    df_long = df.melt(id_vars='Fold', var_name='Metric', value_name='Value')\n",
    "    palette = sns.color_palette(\"muted\", n_colors=len(df_long['Metric'].unique()))\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    for fold in range(3):   \n",
    "        i = fold // 2\n",
    "        j = fold % 2\n",
    "        sns.barplot(x='Metric', y='Value', data=df_long[df_long['Fold'] == fold], ax=axs[i, j], palette=palette)\n",
    "        axs[i, j].set_title(f\"Fold: {fold+1}\")\n",
    "\n",
    "    sns.barplot(x=avg_data.index, y=avg_data.values, ax=axs[1, 1], palette=palette, yerr=errors, capsize=5)\n",
    "    axs[1, 1].set_title(\"Avg. Across Folds\")\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics_fold(res_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 161)\n",
      "[[ 0 14]\n",
      " [ 1 30]\n",
      " [ 2 30]\n",
      " [ 3 46]\n",
      " [ 4 47]]\n",
      "Train size: 133\n",
      "Val size: 34\n"
     ]
    }
   ],
   "source": [
    "A_HR_train = pd.read_csv(\"../data/hr_train.csv\")\n",
    "\n",
    "pca = PCA(n_components=0.99, whiten=False)\n",
    "A_HR_train_pca = pca.fit_transform(A_HR_train)\n",
    "print(A_HR_train_pca.shape)\n",
    "\n",
    "gm = GaussianMixture(n_components=5, random_state=random_seed)\n",
    "A_HR_train_label = gm.fit_predict(A_HR_train_pca)\n",
    "unique, counts = np.unique(A_HR_train_label, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "X = np.load('A_LR_train_matrix.npy')\n",
    "y = np.load('A_HR_train_matrix.npy')\n",
    "\n",
    "n_sample = X.shape[0]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X.reshape(n_sample, -1), \n",
    "    y.reshape(n_sample, -1), \n",
    "    test_size=0.20, \n",
    "    random_state=random_seed,\n",
    "    stratify=A_HR_train_label\n",
    ")\n",
    "\n",
    "X_train = X_train.reshape(-1, LR_size, LR_size)\n",
    "X_val = X_val.reshape(-1, LR_size, LR_size)\n",
    "y_train = y_train.reshape(-1, HR_size, HR_size)\n",
    "y_val = y_val.reshape(-1, HR_size, HR_size)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Val size:\", len(X_val))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   0%|          | 1/200 [00:21<1:12:31, 21.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 2.318177, Train Error: 0.239236, Test Error: 0.201087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   1%|          | 2/200 [00:43<1:11:29, 21.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 1.373000, Train Error: 0.179409, Test Error: 0.171412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   2%|▏         | 3/200 [01:04<1:10:23, 21.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 2.043321, Train Error: 0.172138, Test Error: 0.169621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   2%|▏         | 4/200 [01:26<1:10:02, 21.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 3.160346, Train Error: 0.170658, Test Error: 0.168626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   2%|▎         | 5/200 [01:48<1:10:20, 21.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 4.064565, Train Error: 0.169422, Test Error: 0.167576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   3%|▎         | 6/200 [02:09<1:09:33, 21.51s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 4.681620, Train Error: 0.168084, Test Error: 0.166366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   4%|▎         | 7/200 [02:30<1:09:18, 21.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Loss: 5.034149, Train Error: 0.166384, Test Error: 0.164648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   4%|▍         | 8/200 [02:52<1:09:13, 21.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Loss: 5.156408, Train Error: 0.164507, Test Error: 0.162674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   4%|▍         | 9/200 [03:14<1:08:43, 21.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Loss: 5.144561, Train Error: 0.162346, Test Error: 0.160598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   5%|▌         | 10/200 [03:35<1:08:24, 21.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 4.969817, Train Error: 0.160112, Test Error: 0.158092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   6%|▌         | 11/200 [03:57<1:08:04, 21.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 4.776209, Train Error: 0.158107, Test Error: 0.156530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   6%|▌         | 12/200 [04:18<1:07:27, 21.53s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Loss: 4.736135, Train Error: 0.156166, Test Error: 0.155112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   6%|▋         | 13/200 [04:40<1:07:27, 21.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Loss: 4.898272, Train Error: 0.154277, Test Error: 0.152992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   7%|▋         | 14/200 [05:02<1:07:34, 21.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Loss: 5.195133, Train Error: 0.152460, Test Error: 0.151691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   8%|▊         | 15/200 [05:24<1:06:55, 21.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Loss: 5.472997, Train Error: 0.150994, Test Error: 0.150551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   8%|▊         | 16/200 [05:46<1:06:38, 21.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Loss: 5.789949, Train Error: 0.149465, Test Error: 0.149240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   8%|▊         | 17/200 [06:07<1:05:52, 21.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Loss: 6.088707, Train Error: 0.147930, Test Error: 0.147657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:   9%|▉         | 18/200 [06:29<1:05:39, 21.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train Loss: 6.366004, Train Error: 0.146474, Test Error: 0.146717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  10%|▉         | 19/200 [06:50<1:05:05, 21.58s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train Loss: 6.717819, Train Error: 0.145321, Test Error: 0.146096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  10%|█         | 20/200 [07:12<1:04:36, 21.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 6.989245, Train Error: 0.144352, Test Error: 0.144903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  10%|█         | 21/200 [07:33<1:04:15, 21.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train Loss: 7.269018, Train Error: 0.143450, Test Error: 0.143824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  11%|█         | 22/200 [07:54<1:03:41, 21.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train Loss: 7.557467, Train Error: 0.142552, Test Error: 0.142777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  12%|█▏        | 23/200 [08:16<1:03:09, 21.41s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train Loss: 7.835352, Train Error: 0.141495, Test Error: 0.141689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  12%|█▏        | 24/200 [08:37<1:03:00, 21.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train Loss: 8.078742, Train Error: 0.140585, Test Error: 0.141478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  12%|█▎        | 25/200 [08:59<1:02:40, 21.49s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train Loss: 8.309034, Train Error: 0.139755, Test Error: 0.141179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  13%|█▎        | 26/200 [09:20<1:02:09, 21.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train Loss: 8.447239, Train Error: 0.139047, Test Error: 0.140295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  14%|█▎        | 27/200 [09:46<1:05:57, 22.88s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train Loss: 8.576740, Train Error: 0.138279, Test Error: 0.139830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  14%|█▍        | 28/200 [10:11<1:07:21, 23.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train Loss: 8.670612, Train Error: 0.137507, Test Error: 0.139399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  14%|█▍        | 29/200 [14:46<4:41:42, 98.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train Loss: 8.751353, Train Error: 0.136793, Test Error: 0.139111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  15%|█▌        | 30/200 [15:11<3:37:39, 76.82s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train Loss: 8.847031, Train Error: 0.136223, Test Error: 0.138823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  16%|█▌        | 31/200 [15:33<2:49:44, 60.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train Loss: 8.904030, Train Error: 0.135874, Test Error: 0.138194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  16%|█▌        | 32/200 [15:55<2:16:35, 48.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train Loss: 8.956477, Train Error: 0.135639, Test Error: 0.137698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  16%|█▋        | 33/200 [16:17<1:53:03, 40.62s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train Loss: 9.105234, Train Error: 0.135108, Test Error: 0.136736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  17%|█▋        | 34/200 [16:38<1:36:41, 34.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train Loss: 9.112586, Train Error: 0.134347, Test Error: 0.136334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  18%|█▊        | 35/200 [17:00<1:25:20, 31.04s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train Loss: 9.085787, Train Error: 0.133900, Test Error: 0.136320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  18%|█▊        | 36/200 [17:22<1:17:33, 28.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train Loss: 9.162064, Train Error: 0.133582, Test Error: 0.136603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  18%|█▊        | 37/200 [17:44<1:11:41, 26.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train Loss: 9.172298, Train Error: 0.132872, Test Error: 0.136162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  19%|█▉        | 38/200 [18:06<1:07:39, 25.06s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train Loss: 9.149638, Train Error: 0.132187, Test Error: 0.135940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  20%|█▉        | 39/200 [18:28<1:04:31, 24.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train Loss: 9.121087, Train Error: 0.131607, Test Error: 0.135560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  20%|██        | 40/200 [18:49<1:02:11, 23.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train Loss: 9.059390, Train Error: 0.131038, Test Error: 0.135902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  20%|██        | 41/200 [19:13<1:02:05, 23.43s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train Loss: 9.041131, Train Error: 0.130615, Test Error: 0.135578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  21%|██        | 42/200 [35:42<13:44:37, 313.15s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train Loss: 9.057712, Train Error: 0.130595, Test Error: 0.135536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  22%|██▏       | 43/200 [36:41<10:19:31, 236.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train Loss: 9.218403, Train Error: 0.130689, Test Error: 0.135792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  22%|██▏       | 44/200 [38:38<8:42:33, 200.98s/epoch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train Loss: 9.379411, Train Error: 0.130557, Test Error: 0.135822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  22%|██▎       | 45/200 [44:08<10:19:07, 239.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train Loss: 9.388696, Train Error: 0.130099, Test Error: 0.135396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  23%|██▎       | 46/200 [50:23<11:59:13, 280.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train Loss: 9.469347, Train Error: 0.129917, Test Error: 0.134624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  24%|██▎       | 47/200 [1:16:25<28:15:07, 664.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train Loss: 9.502012, Train Error: 0.129402, Test Error: 0.134346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  24%|██▍       | 48/200 [1:18:14<21:01:27, 497.94s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train Loss: 9.692938, Train Error: 0.129276, Test Error: 0.134480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  24%|██▍       | 49/200 [1:18:37<14:54:53, 355.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train Loss: 9.830607, Train Error: 0.129308, Test Error: 0.134226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  25%|██▌       | 50/200 [1:18:59<10:38:42, 255.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train Loss: 9.986336, Train Error: 0.128877, Test Error: 0.134132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  26%|██▌       | 51/200 [1:19:21<7:40:37, 185.48s/epoch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Train Loss: 10.024916, Train Error: 0.128336, Test Error: 0.134210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  26%|██▌       | 52/200 [1:19:45<5:37:32, 136.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Train Loss: 10.117257, Train Error: 0.128175, Test Error: 0.133975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  26%|██▋       | 53/200 [1:20:08<4:11:37, 102.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Train Loss: 10.011216, Train Error: 0.127780, Test Error: 0.134264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  27%|██▋       | 54/200 [1:20:34<3:13:52, 79.67s/epoch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Train Loss: 9.956398, Train Error: 0.127358, Test Error: 0.134428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  28%|██▊       | 55/200 [1:21:01<2:34:46, 64.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Train Loss: 9.904143, Train Error: 0.127243, Test Error: 0.134364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  28%|██▊       | 56/200 [1:21:25<2:04:32, 51.89s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Train Loss: 9.795807, Train Error: 0.127133, Test Error: 0.134277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  28%|██▊       | 57/200 [1:21:49<1:43:35, 43.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Train Loss: 9.761261, Train Error: 0.126785, Test Error: 0.134085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress:  28%|██▊       | 57/200 [1:22:16<3:26:25, 86.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Error: 0.133975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "netG = GSRNet(ks, args).to(device)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=args.lr)\n",
    "\n",
    "netD = Discriminator(args).to(device)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=args.lr)\n",
    "\n",
    "final_model = train_gan(\n",
    "    netG, \n",
    "    optimizerG, \n",
    "    netD,\n",
    "    optimizerD,\n",
    "    X_train, \n",
    "    y_train, \n",
    "    args, \n",
    "    test_adj=X_val, \n",
    "    test_ground_truth=y_val\n",
    ")\n",
    "# final_model = train(netG, optimizerG, X_train, y_train, args, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:01<00:00, 81.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.1285266478863747\n",
      "PCC:  0.6745766270363869\n",
      "Jensen-Shannon Distance:  0.27543885189030015\n",
      "Val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 92.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.13397503231917554\n",
      "PCC:  0.6461689894033666\n",
      "Jensen-Shannon Distance:  0.27788996009861194\n"
     ]
    }
   ],
   "source": [
    "final_model.eval()\n",
    "pred_train_matrices = np.zeros(y_train.shape)\n",
    "pred_val_matrices = np.zeros(y_val.shape)\n",
    "with torch.no_grad():\n",
    "    for j, test_adj in enumerate(X_train):\n",
    "        pred_train_matrices[j], _, _, _ = final_model(torch.from_numpy(test_adj))\n",
    "\n",
    "    print(\"Train\")\n",
    "    evaluate(pred_train_matrices, y_train)\n",
    "\n",
    "    for j, test_adj in enumerate(X_val):\n",
    "        pred_val_matrices[j], _, _, _ = final_model(torch.from_numpy(test_adj))\n",
    "\n",
    "    print(\"Val\")\n",
    "    evaluate(pred_val_matrices, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_list = []\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(A_LR_test_matrix.shape[0]):\n",
    "        output_pred, _, _, _ = final_model(torch.Tensor(A_LR_test_matrix[i]))\n",
    "        output_pred = MatrixVectorizer.vectorize(output_pred).tolist()\n",
    "        output_pred_list.append(output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_stack = np.stack(output_pred_list, axis=0)\n",
    "output_pred_1d = output_pred_stack.flatten()\n",
    "assert output_pred_1d.shape == (4007136, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.585028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.496612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.694167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.536072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.502271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007131</th>\n",
       "      <td>4007132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007132</th>\n",
       "      <td>4007133</td>\n",
       "      <td>0.019808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007133</th>\n",
       "      <td>4007134</td>\n",
       "      <td>0.272116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007134</th>\n",
       "      <td>4007135</td>\n",
       "      <td>0.090878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007135</th>\n",
       "      <td>4007136</td>\n",
       "      <td>0.365271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4007136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  Predicted\n",
       "0              1   0.585028\n",
       "1              2   0.496612\n",
       "2              3   0.694167\n",
       "3              4   0.536072\n",
       "4              5   0.502271\n",
       "...          ...        ...\n",
       "4007131  4007132   0.000000\n",
       "4007132  4007133   0.019808\n",
       "4007133  4007134   0.272116\n",
       "4007134  4007135   0.090878\n",
       "4007135  4007136   0.365271\n",
       "\n",
       "[4007136 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"ID\": [i+1 for i in range(len(output_pred_1d))],\n",
    "    \"Predicted\": output_pred_1d.tolist()\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"gsr_gan_gat_relu.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
