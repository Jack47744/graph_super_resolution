{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MatrixVectorizer import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_LR_train = pd.read_csv(\"../data/lr_train.csv\")\n",
    "# A_HR_train = pd.read_csv(\"../data/hr_train.csv\")\n",
    "# A_LR_test = pd.read_csv(\"../data/lr_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_size = 160\n",
    "HR_size = 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatrixVectorizer = MatrixVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_subject = A_LR_train.shape[0]\n",
    "# A_LR_train_matrix = np.zeros((num_subject, LR_size, LR_size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "# for i in range(num_subject):\n",
    "#     A_LR_train_matrix[i] = MatrixVectorizer.anti_vectorize(A_LR_train.iloc[i], LR_size) # torch.from_numpy(MatrixVectorizer.anti_vectorize(A_LR_train.iloc[i], LR_size))\n",
    "\n",
    "# A_HR_train_matrix = np.zeros((num_subject, HR_size, HR_size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "# for i in range(num_subject):\n",
    "#     A_HR_train_matrix[i] = MatrixVectorizer.anti_vectorize(A_HR_train.iloc[i], HR_size) \n",
    "\n",
    "# num_subject = len(A_LR_test)\n",
    "# A_LR_test_matrix = np.zeros((num_subject, LR_size, LR_size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "# for i in range(num_subject):\n",
    "#     A_LR_test_matrix[i] = MatrixVectorizer.anti_vectorize(A_LR_test.iloc[i], LR_size) \n",
    "\n",
    "# np.save('A_LR_train_matrix.npy', A_LR_train_matrix)\n",
    "# np.save('A_HR_train_matrix.npy', A_HR_train_matrix)\n",
    "# np.save('A_LR_test_matrix.npy', A_LR_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 160, 160)\n",
      "(167, 268, 268)\n",
      "(112, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "A_LR_train_matrix = np.load('A_LR_train_matrix.npy')\n",
    "A_HR_train_matrix = np.load('A_HR_train_matrix.npy')\n",
    "A_LR_test_matrix = np.load(\"A_LR_test_matrix.npy\")\n",
    "\n",
    "print(A_LR_train_matrix.shape)\n",
    "print(A_HR_train_matrix.shape)\n",
    "print(A_LR_test_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=200, lr=0.0001, splits=3, lmbda=16, lr_dim=160, hr_dim=268, hidden_dim=280, padding=26)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function of Graph Super-Resolution Network (GSR-Net) framework \n",
    "   for predicting high-resolution brain connectomes from low-resolution connectomes. \n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    This file contains the implementation of the training and testing process of our GSR-Net model.\n",
    "        train(model, optimizer, subjects_adj, subjects_ground_truth, args)\n",
    "\n",
    "                Inputs:\n",
    "                        model:        constructor of our GSR-Net model:  model = GSRNet(ks,args)\n",
    "                                      ks:   array that stores reduction rates of nodes in Graph U-Net pooling layers\n",
    "                                      args: parsed command line arguments\n",
    "\n",
    "                        optimizer:    constructor of our model's optimizer (borrowed from PyTorch)  \n",
    "\n",
    "                        subjects_adj: (n × l x l) tensor stacking LR connectivity matrices of all training subjects\n",
    "                                       n: the total number of subjects\n",
    "                                       l: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        subjects_ground_truth: (n × h x h) tensor stacking LR connectivity matrices of all training subjects\n",
    "                                                n: the total number of subjects\n",
    "                                                h: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        args:          parsed command line arguments, to learn more about the arguments run: \n",
    "                                       python demo.py --help\n",
    "                Output:\n",
    "                        for each epoch, prints out the mean training MSE error\n",
    "\n",
    "\n",
    "            \n",
    "        test(model, test_adj,test_ground_truth,args)\n",
    "\n",
    "                Inputs:\n",
    "                        test_adj:      (n × l x l) tensor stacking LR connectivity matrices of all testing subjects\n",
    "                                        n: the total number of subjects\n",
    "                                        l: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        test_ground_truth:      (n × h x h) tensor stacking LR connectivity matrices of all testing subjects\n",
    "                                                 n: the total number of subjects\n",
    "                                                 h: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        see train method above for model and args.\n",
    "\n",
    "                Outputs:\n",
    "                        for each epoch, prints out the mean testing MSE error\n",
    "\n",
    "\n",
    "    To evaluate our framework we used 5-fold cross-validation strategy.\n",
    "\n",
    "    ---------------------------------------------------------------------\n",
    "    Copyright 2020 Megi Isallari, Istanbul Technical University.\n",
    "    All rights reserved.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "from train import *\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GSR-Net')\n",
    "parser.add_argument('--epochs', type=int, default=epochs, metavar='no_epochs',\n",
    "                help='number of episode to train ')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, metavar='lr',\n",
    "                help='learning rate (default: 0.0001 using Adam Optimizer)')\n",
    "parser.add_argument('--splits', type=int, default=3, metavar='n_splits',\n",
    "                help='no of cross validation folds')\n",
    "parser.add_argument('--lmbda', type=int, default=16, metavar='L',\n",
    "                help='self-reconstruction error hyperparameter')\n",
    "parser.add_argument('--lr_dim', type=int, default=LR_size, metavar='N',\n",
    "                help='adjacency matrix input dimensions')\n",
    "parser.add_argument('--hr_dim', type=int, default=HR_size, metavar='N',\n",
    "                help='super-resolved adjacency matrix output dimensions')\n",
    "parser.add_argument('--hidden_dim', type=int, default=280, metavar='N',\n",
    "                help='hidden GraphConvolutional layer dimensions')\n",
    "parser.add_argument('--padding', type=int, default=26, metavar='padding',\n",
    "                help='dimensions of padding')\n",
    "\n",
    "# Create an empty Namespace to hold the default arguments\n",
    "args = parser.parse_args([]) \n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 160, 160)\n",
      "(167, 268, 268)\n"
     ]
    }
   ],
   "source": [
    "# SIMULATING THE DATA: EDIT TO ENTER YOUR OWN DATA\n",
    "X = A_LR_train_matrix #np.random.normal(0, 0.5, (167, 160, 160))\n",
    "Y = A_HR_train_matrix #np.random.normal(0, 0.5, (167, 288, 288))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: \n",
      "Epoch: 0, Train Loss: 0.108893, Train Error: 0.235015, Test Error: 0.200097\n",
      "Epoch: 1, Train Loss: 0.076798, Train Error: 0.201993, Test Error: 0.187153\n",
      "Epoch: 2, Train Loss: 0.069928, Train Error: 0.194683, Test Error: 0.183119\n",
      "Epoch: 3, Train Loss: 0.066835, Train Error: 0.191793, Test Error: 0.181274\n",
      "Epoch: 4, Train Loss: 0.065099, Train Error: 0.190318, Test Error: 0.180233\n",
      "Epoch: 5, Train Loss: 0.064108, Train Error: 0.189582, Test Error: 0.179738\n",
      "Epoch: 6, Train Loss: 0.063480, Train Error: 0.189144, Test Error: 0.179513\n",
      "Epoch: 7, Train Loss: 0.063043, Train Error: 0.188854, Test Error: 0.179449\n",
      "Epoch: 8, Train Loss: 0.062712, Train Error: 0.188622, Test Error: 0.179400\n",
      "Epoch: 9, Train Loss: 0.062443, Train Error: 0.188413, Test Error: 0.179294\n",
      "Epoch: 10, Train Loss: 0.062215, Train Error: 0.188219, Test Error: 0.179194\n",
      "Epoch: 11, Train Loss: 0.062005, Train Error: 0.188023, Test Error: 0.179081\n",
      "Epoch: 12, Train Loss: 0.061794, Train Error: 0.187808, Test Error: 0.178938\n",
      "Epoch: 13, Train Loss: 0.061601, Train Error: 0.187608, Test Error: 0.178839\n",
      "Epoch: 14, Train Loss: 0.061419, Train Error: 0.187412, Test Error: 0.178734\n",
      "Epoch: 15, Train Loss: 0.061224, Train Error: 0.187196, Test Error: 0.178570\n",
      "Epoch: 16, Train Loss: 0.061038, Train Error: 0.186979, Test Error: 0.178398\n",
      "Epoch: 17, Train Loss: 0.060811, Train Error: 0.186692, Test Error: 0.178151\n",
      "Epoch: 18, Train Loss: 0.060558, Train Error: 0.186354, Test Error: 0.177937\n",
      "Epoch: 19, Train Loss: 0.060236, Train Error: 0.185900, Test Error: 0.177555\n",
      "Epoch: 20, Train Loss: 0.059846, Train Error: 0.185332, Test Error: 0.177151\n",
      "Epoch: 21, Train Loss: 0.059373, Train Error: 0.184629, Test Error: 0.176606\n",
      "Epoch: 22, Train Loss: 0.058798, Train Error: 0.183757, Test Error: 0.175854\n",
      "Epoch: 23, Train Loss: 0.058061, Train Error: 0.182630, Test Error: 0.174915\n",
      "Epoch: 24, Train Loss: 0.057212, Train Error: 0.181300, Test Error: 0.173771\n",
      "Epoch: 25, Train Loss: 0.056170, Train Error: 0.179675, Test Error: 0.172365\n",
      "Epoch: 26, Train Loss: 0.055004, Train Error: 0.177866, Test Error: 0.170957\n",
      "Epoch: 27, Train Loss: 0.053910, Train Error: 0.176190, Test Error: 0.169939\n",
      "Epoch: 28, Train Loss: 0.053001, Train Error: 0.174784, Test Error: 0.169068\n",
      "Epoch: 29, Train Loss: 0.052254, Train Error: 0.173614, Test Error: 0.168400\n",
      "Epoch: 30, Train Loss: 0.051695, Train Error: 0.172709, Test Error: 0.168140\n",
      "Epoch: 31, Train Loss: 0.051186, Train Error: 0.171856, Test Error: 0.167758\n",
      "Epoch: 32, Train Loss: 0.050738, Train Error: 0.171038, Test Error: 0.167386\n",
      "Epoch: 33, Train Loss: 0.050336, Train Error: 0.170289, Test Error: 0.167110\n",
      "Epoch: 34, Train Loss: 0.049959, Train Error: 0.169563, Test Error: 0.166679\n",
      "Epoch: 35, Train Loss: 0.049577, Train Error: 0.168797, Test Error: 0.166424\n",
      "Epoch: 36, Train Loss: 0.049199, Train Error: 0.168037, Test Error: 0.166187\n",
      "Epoch: 37, Train Loss: 0.048787, Train Error: 0.167194, Test Error: 0.165887\n",
      "Epoch: 38, Train Loss: 0.048389, Train Error: 0.166354, Test Error: 0.165560\n",
      "Epoch: 39, Train Loss: 0.048010, Train Error: 0.165540, Test Error: 0.165156\n",
      "Epoch: 40, Train Loss: 0.047587, Train Error: 0.164627, Test Error: 0.164765\n",
      "Epoch: 41, Train Loss: 0.047211, Train Error: 0.163767, Test Error: 0.164356\n",
      "Epoch: 42, Train Loss: 0.046830, Train Error: 0.162909, Test Error: 0.163925\n",
      "Epoch: 43, Train Loss: 0.046453, Train Error: 0.162056, Test Error: 0.163467\n",
      "Epoch: 44, Train Loss: 0.046117, Train Error: 0.161296, Test Error: 0.163036\n",
      "Epoch: 45, Train Loss: 0.045748, Train Error: 0.160461, Test Error: 0.162634\n",
      "Epoch: 46, Train Loss: 0.045419, Train Error: 0.159709, Test Error: 0.162077\n",
      "Epoch: 47, Train Loss: 0.045074, Train Error: 0.158909, Test Error: 0.161602\n",
      "Epoch: 48, Train Loss: 0.044753, Train Error: 0.158182, Test Error: 0.161110\n",
      "Epoch: 49, Train Loss: 0.044436, Train Error: 0.157447, Test Error: 0.160633\n",
      "Epoch: 50, Train Loss: 0.044147, Train Error: 0.156770, Test Error: 0.160041\n",
      "Epoch: 51, Train Loss: 0.043850, Train Error: 0.156079, Test Error: 0.159593\n",
      "Epoch: 52, Train Loss: 0.043617, Train Error: 0.155522, Test Error: 0.159138\n",
      "Epoch: 53, Train Loss: 0.043333, Train Error: 0.154852, Test Error: 0.158674\n",
      "Epoch: 54, Train Loss: 0.043070, Train Error: 0.154221, Test Error: 0.158236\n",
      "Epoch: 55, Train Loss: 0.042778, Train Error: 0.153548, Test Error: 0.157878\n",
      "Epoch: 56, Train Loss: 0.042557, Train Error: 0.153015, Test Error: 0.157457\n",
      "Epoch: 57, Train Loss: 0.042304, Train Error: 0.152428, Test Error: 0.157183\n",
      "Epoch: 58, Train Loss: 0.042108, Train Error: 0.151953, Test Error: 0.156855\n",
      "Epoch: 59, Train Loss: 0.041840, Train Error: 0.151360, Test Error: 0.156513\n",
      "Epoch: 60, Train Loss: 0.041667, Train Error: 0.150917, Test Error: 0.156071\n",
      "Epoch: 61, Train Loss: 0.041426, Train Error: 0.150360, Test Error: 0.155697\n",
      "Epoch: 62, Train Loss: 0.041276, Train Error: 0.149990, Test Error: 0.155371\n",
      "Epoch: 63, Train Loss: 0.041014, Train Error: 0.149400, Test Error: 0.154955\n",
      "Epoch: 64, Train Loss: 0.040840, Train Error: 0.148988, Test Error: 0.154519\n",
      "Epoch: 65, Train Loss: 0.040617, Train Error: 0.148453, Test Error: 0.154270\n",
      "Epoch: 66, Train Loss: 0.040462, Train Error: 0.148075, Test Error: 0.153925\n",
      "Epoch: 67, Train Loss: 0.040259, Train Error: 0.147574, Test Error: 0.153726\n",
      "Epoch: 68, Train Loss: 0.040092, Train Error: 0.147201, Test Error: 0.153508\n",
      "Epoch: 69, Train Loss: 0.039879, Train Error: 0.146706, Test Error: 0.153182\n",
      "Epoch: 70, Train Loss: 0.039698, Train Error: 0.146303, Test Error: 0.152990\n",
      "Epoch: 71, Train Loss: 0.039520, Train Error: 0.145896, Test Error: 0.152732\n",
      "Epoch: 72, Train Loss: 0.039366, Train Error: 0.145538, Test Error: 0.152527\n",
      "Epoch: 73, Train Loss: 0.039161, Train Error: 0.145051, Test Error: 0.152229\n",
      "Epoch: 74, Train Loss: 0.039012, Train Error: 0.144691, Test Error: 0.151911\n",
      "Epoch: 75, Train Loss: 0.038868, Train Error: 0.144347, Test Error: 0.151666\n",
      "Epoch: 76, Train Loss: 0.038726, Train Error: 0.143994, Test Error: 0.151508\n",
      "Epoch: 77, Train Loss: 0.038574, Train Error: 0.143631, Test Error: 0.151401\n",
      "Epoch: 78, Train Loss: 0.038434, Train Error: 0.143306, Test Error: 0.151107\n",
      "Epoch: 79, Train Loss: 0.038281, Train Error: 0.142963, Test Error: 0.150935\n",
      "Epoch: 80, Train Loss: 0.038157, Train Error: 0.142680, Test Error: 0.150659\n",
      "Epoch: 81, Train Loss: 0.038020, Train Error: 0.142358, Test Error: 0.150444\n",
      "Epoch: 82, Train Loss: 0.037904, Train Error: 0.142093, Test Error: 0.150350\n",
      "Epoch: 83, Train Loss: 0.037760, Train Error: 0.141751, Test Error: 0.150090\n",
      "Epoch: 84, Train Loss: 0.037644, Train Error: 0.141490, Test Error: 0.150029\n",
      "Epoch: 85, Train Loss: 0.037528, Train Error: 0.141211, Test Error: 0.149793\n",
      "Epoch: 86, Train Loss: 0.037432, Train Error: 0.140998, Test Error: 0.149601\n",
      "Epoch: 87, Train Loss: 0.037315, Train Error: 0.140732, Test Error: 0.149316\n",
      "Epoch: 88, Train Loss: 0.037219, Train Error: 0.140515, Test Error: 0.149144\n",
      "Epoch: 89, Train Loss: 0.037099, Train Error: 0.140244, Test Error: 0.149026\n",
      "Epoch: 90, Train Loss: 0.036997, Train Error: 0.140037, Test Error: 0.148870\n",
      "Epoch: 91, Train Loss: 0.036878, Train Error: 0.139787, Test Error: 0.148687\n",
      "Epoch: 92, Train Loss: 0.036778, Train Error: 0.139587, Test Error: 0.148573\n",
      "Epoch: 93, Train Loss: 0.036636, Train Error: 0.139255, Test Error: 0.148290\n",
      "Epoch: 94, Train Loss: 0.036534, Train Error: 0.139045, Test Error: 0.148226\n",
      "Epoch: 95, Train Loss: 0.036417, Train Error: 0.138780, Test Error: 0.148093\n",
      "Epoch: 96, Train Loss: 0.036336, Train Error: 0.138633, Test Error: 0.148048\n",
      "Epoch: 97, Train Loss: 0.036238, Train Error: 0.138412, Test Error: 0.147931\n",
      "Epoch: 98, Train Loss: 0.036138, Train Error: 0.138208, Test Error: 0.147877\n",
      "Epoch: 99, Train Loss: 0.036018, Train Error: 0.137941, Test Error: 0.147678\n",
      "Epoch: 100, Train Loss: 0.035916, Train Error: 0.137758, Test Error: 0.147613\n",
      "Epoch: 101, Train Loss: 0.035801, Train Error: 0.137518, Test Error: 0.147387\n",
      "Epoch: 102, Train Loss: 0.035711, Train Error: 0.137344, Test Error: 0.147356\n",
      "Epoch: 103, Train Loss: 0.035617, Train Error: 0.137123, Test Error: 0.147125\n",
      "Epoch: 104, Train Loss: 0.035585, Train Error: 0.137114, Test Error: 0.147152\n",
      "Epoch: 105, Train Loss: 0.035524, Train Error: 0.137010, Test Error: 0.147190\n",
      "Epoch: 106, Train Loss: 0.035481, Train Error: 0.136952, Test Error: 0.147142\n",
      "Epoch: 107, Train Loss: 0.035364, Train Error: 0.136705, Test Error: 0.146925\n",
      "Epoch: 108, Train Loss: 0.035302, Train Error: 0.136606, Test Error: 0.147255\n",
      "Epoch: 109, Train Loss: 0.035793, Train Error: 0.137825, Test Error: 0.147304\n",
      "Epoch: 110, Train Loss: 0.035826, Train Error: 0.137999, Test Error: 0.147564\n",
      "Epoch: 0, Train Loss: 0.105731, Train Error: 0.232127, Test Error: 0.208262\n",
      "Epoch: 1, Train Loss: 0.074245, Train Error: 0.199003, Test Error: 0.193758\n",
      "Epoch: 2, Train Loss: 0.065979, Train Error: 0.188809, Test Error: 0.187026\n",
      "Epoch: 3, Train Loss: 0.061280, Train Error: 0.183266, Test Error: 0.183046\n",
      "Epoch: 4, Train Loss: 0.058617, Train Error: 0.180655, Test Error: 0.181806\n",
      "Epoch: 5, Train Loss: 0.057523, Train Error: 0.179830, Test Error: 0.181357\n",
      "Epoch: 6, Train Loss: 0.056923, Train Error: 0.179387, Test Error: 0.181175\n",
      "Epoch: 7, Train Loss: 0.056546, Train Error: 0.179136, Test Error: 0.181076\n",
      "Epoch: 8, Train Loss: 0.056301, Train Error: 0.179013, Test Error: 0.180974\n",
      "Epoch: 9, Train Loss: 0.056079, Train Error: 0.178862, Test Error: 0.180869\n",
      "Epoch: 10, Train Loss: 0.055861, Train Error: 0.178666, Test Error: 0.180759\n",
      "Epoch: 11, Train Loss: 0.055658, Train Error: 0.178469, Test Error: 0.180601\n",
      "Epoch: 12, Train Loss: 0.055485, Train Error: 0.178297, Test Error: 0.180484\n",
      "Epoch: 13, Train Loss: 0.055331, Train Error: 0.178141, Test Error: 0.180368\n",
      "Epoch: 14, Train Loss: 0.055188, Train Error: 0.177991, Test Error: 0.180218\n",
      "Epoch: 15, Train Loss: 0.055060, Train Error: 0.177845, Test Error: 0.180093\n",
      "Epoch: 16, Train Loss: 0.054912, Train Error: 0.177656, Test Error: 0.179968\n",
      "Epoch: 17, Train Loss: 0.054780, Train Error: 0.177479, Test Error: 0.179819\n",
      "Epoch: 18, Train Loss: 0.054622, Train Error: 0.177246, Test Error: 0.179742\n",
      "Epoch: 19, Train Loss: 0.054474, Train Error: 0.177029, Test Error: 0.179637\n",
      "Epoch: 20, Train Loss: 0.054324, Train Error: 0.176794, Test Error: 0.179494\n",
      "Epoch: 21, Train Loss: 0.054139, Train Error: 0.176498, Test Error: 0.179308\n",
      "Epoch: 22, Train Loss: 0.053967, Train Error: 0.176232, Test Error: 0.179160\n",
      "Epoch: 23, Train Loss: 0.053767, Train Error: 0.175903, Test Error: 0.178995\n",
      "Epoch: 24, Train Loss: 0.053546, Train Error: 0.175529, Test Error: 0.178815\n",
      "Epoch: 25, Train Loss: 0.053302, Train Error: 0.175094, Test Error: 0.178537\n",
      "Epoch: 26, Train Loss: 0.053045, Train Error: 0.174611, Test Error: 0.178315\n",
      "Epoch: 27, Train Loss: 0.052756, Train Error: 0.174104, Test Error: 0.177989\n",
      "Epoch: 28, Train Loss: 0.052399, Train Error: 0.173460, Test Error: 0.177624\n",
      "Epoch: 29, Train Loss: 0.052030, Train Error: 0.172787, Test Error: 0.177105\n",
      "Epoch: 30, Train Loss: 0.051660, Train Error: 0.172084, Test Error: 0.176636\n",
      "Epoch: 31, Train Loss: 0.051247, Train Error: 0.171293, Test Error: 0.176036\n",
      "Epoch: 32, Train Loss: 0.050824, Train Error: 0.170496, Test Error: 0.175479\n",
      "Epoch: 33, Train Loss: 0.050350, Train Error: 0.169583, Test Error: 0.174823\n",
      "Epoch: 34, Train Loss: 0.049854, Train Error: 0.168607, Test Error: 0.174160\n",
      "Epoch: 35, Train Loss: 0.049323, Train Error: 0.167572, Test Error: 0.173452\n",
      "Epoch: 36, Train Loss: 0.048787, Train Error: 0.166516, Test Error: 0.172618\n",
      "Epoch: 37, Train Loss: 0.048242, Train Error: 0.165421, Test Error: 0.171825\n",
      "Epoch: 38, Train Loss: 0.047697, Train Error: 0.164310, Test Error: 0.170979\n",
      "Epoch: 39, Train Loss: 0.047163, Train Error: 0.163236, Test Error: 0.170013\n",
      "Epoch: 40, Train Loss: 0.046568, Train Error: 0.162059, Test Error: 0.169245\n",
      "Epoch: 41, Train Loss: 0.045995, Train Error: 0.160896, Test Error: 0.168331\n",
      "Epoch: 42, Train Loss: 0.045366, Train Error: 0.159627, Test Error: 0.167537\n",
      "Epoch: 43, Train Loss: 0.044784, Train Error: 0.158472, Test Error: 0.166705\n",
      "Epoch: 44, Train Loss: 0.044112, Train Error: 0.157161, Test Error: 0.165977\n",
      "Epoch: 45, Train Loss: 0.043553, Train Error: 0.156077, Test Error: 0.165091\n",
      "Epoch: 46, Train Loss: 0.042878, Train Error: 0.154767, Test Error: 0.164111\n",
      "Epoch: 47, Train Loss: 0.042287, Train Error: 0.153604, Test Error: 0.163243\n",
      "Epoch: 48, Train Loss: 0.041708, Train Error: 0.152498, Test Error: 0.162594\n",
      "Epoch: 49, Train Loss: 0.041135, Train Error: 0.151359, Test Error: 0.161788\n",
      "Epoch: 50, Train Loss: 0.040623, Train Error: 0.150372, Test Error: 0.161165\n",
      "Epoch: 51, Train Loss: 0.040123, Train Error: 0.149423, Test Error: 0.160552\n",
      "Epoch: 52, Train Loss: 0.039698, Train Error: 0.148607, Test Error: 0.160083\n",
      "Epoch: 53, Train Loss: 0.039319, Train Error: 0.147845, Test Error: 0.159595\n",
      "Epoch: 54, Train Loss: 0.038950, Train Error: 0.147056, Test Error: 0.159130\n",
      "Epoch: 55, Train Loss: 0.038552, Train Error: 0.146192, Test Error: 0.158681\n",
      "Epoch: 56, Train Loss: 0.038179, Train Error: 0.145373, Test Error: 0.158285\n",
      "Epoch: 57, Train Loss: 0.037859, Train Error: 0.144656, Test Error: 0.157968\n",
      "Epoch: 58, Train Loss: 0.037555, Train Error: 0.143960, Test Error: 0.157653\n",
      "Epoch: 59, Train Loss: 0.037280, Train Error: 0.143320, Test Error: 0.157339\n",
      "Epoch: 60, Train Loss: 0.037022, Train Error: 0.142711, Test Error: 0.157065\n",
      "Epoch: 61, Train Loss: 0.036784, Train Error: 0.142135, Test Error: 0.156837\n",
      "Epoch: 62, Train Loss: 0.036549, Train Error: 0.141568, Test Error: 0.156566\n",
      "Epoch: 63, Train Loss: 0.036323, Train Error: 0.141004, Test Error: 0.156350\n",
      "Epoch: 64, Train Loss: 0.036112, Train Error: 0.140482, Test Error: 0.156143\n",
      "Epoch: 65, Train Loss: 0.035923, Train Error: 0.139998, Test Error: 0.155954\n",
      "Epoch: 66, Train Loss: 0.035727, Train Error: 0.139508, Test Error: 0.155736\n",
      "Epoch: 67, Train Loss: 0.035557, Train Error: 0.139066, Test Error: 0.155539\n",
      "Epoch: 68, Train Loss: 0.035394, Train Error: 0.138656, Test Error: 0.155375\n",
      "Epoch: 69, Train Loss: 0.035240, Train Error: 0.138251, Test Error: 0.155222\n",
      "Epoch: 70, Train Loss: 0.035087, Train Error: 0.137853, Test Error: 0.155112\n",
      "Epoch: 71, Train Loss: 0.034941, Train Error: 0.137448, Test Error: 0.154984\n",
      "Epoch: 72, Train Loss: 0.034777, Train Error: 0.137035, Test Error: 0.154884\n",
      "Epoch: 73, Train Loss: 0.034646, Train Error: 0.136684, Test Error: 0.154738\n",
      "Epoch: 74, Train Loss: 0.034514, Train Error: 0.136350, Test Error: 0.154655\n",
      "Epoch: 75, Train Loss: 0.034394, Train Error: 0.136000, Test Error: 0.154545\n",
      "Epoch: 76, Train Loss: 0.034261, Train Error: 0.135676, Test Error: 0.154472\n",
      "Epoch: 77, Train Loss: 0.034134, Train Error: 0.135323, Test Error: 0.154420\n",
      "Epoch: 78, Train Loss: 0.034030, Train Error: 0.135051, Test Error: 0.154315\n",
      "Epoch: 79, Train Loss: 0.033934, Train Error: 0.134776, Test Error: 0.154223\n",
      "Epoch: 80, Train Loss: 0.033838, Train Error: 0.134531, Test Error: 0.154051\n",
      "Epoch: 81, Train Loss: 0.033734, Train Error: 0.134230, Test Error: 0.154004\n",
      "Epoch: 82, Train Loss: 0.033619, Train Error: 0.133938, Test Error: 0.153883\n",
      "Epoch: 83, Train Loss: 0.033521, Train Error: 0.133645, Test Error: 0.153801\n",
      "Epoch: 84, Train Loss: 0.033417, Train Error: 0.133392, Test Error: 0.153754\n",
      "Epoch: 85, Train Loss: 0.033318, Train Error: 0.133105, Test Error: 0.153728\n",
      "Epoch: 86, Train Loss: 0.033236, Train Error: 0.132918, Test Error: 0.153679\n",
      "Epoch: 87, Train Loss: 0.033175, Train Error: 0.132735, Test Error: 0.153722\n",
      "Epoch: 88, Train Loss: 0.033091, Train Error: 0.132554, Test Error: 0.153664\n",
      "Epoch: 89, Train Loss: 0.033019, Train Error: 0.132321, Test Error: 0.153697\n",
      "Epoch: 90, Train Loss: 0.032928, Train Error: 0.132108, Test Error: 0.153670\n",
      "Epoch: 91, Train Loss: 0.032862, Train Error: 0.131900, Test Error: 0.153741\n",
      "Epoch: 0, Train Loss: 0.105292, Train Error: 0.230168, Test Error: 0.202116\n",
      "Epoch: 1, Train Loss: 0.074455, Train Error: 0.199154, Test Error: 0.191232\n",
      "Epoch: 2, Train Loss: 0.068372, Train Error: 0.192322, Test Error: 0.186367\n",
      "Epoch: 3, Train Loss: 0.064696, Train Error: 0.188081, Test Error: 0.182594\n",
      "Epoch: 4, Train Loss: 0.061330, Train Error: 0.183856, Test Error: 0.178605\n",
      "Epoch: 5, Train Loss: 0.058824, Train Error: 0.181152, Test Error: 0.176923\n",
      "Epoch: 6, Train Loss: 0.057482, Train Error: 0.179892, Test Error: 0.176203\n",
      "Epoch: 7, Train Loss: 0.056743, Train Error: 0.179280, Test Error: 0.175925\n",
      "Epoch: 8, Train Loss: 0.056269, Train Error: 0.178864, Test Error: 0.175720\n",
      "Epoch: 9, Train Loss: 0.055941, Train Error: 0.178569, Test Error: 0.175595\n",
      "Epoch: 10, Train Loss: 0.055677, Train Error: 0.178331, Test Error: 0.175519\n",
      "Epoch: 11, Train Loss: 0.055445, Train Error: 0.178113, Test Error: 0.175459\n",
      "Epoch: 12, Train Loss: 0.055236, Train Error: 0.177898, Test Error: 0.175363\n",
      "Epoch: 13, Train Loss: 0.055046, Train Error: 0.177691, Test Error: 0.175244\n",
      "Epoch: 14, Train Loss: 0.054870, Train Error: 0.177487, Test Error: 0.175141\n",
      "Epoch: 15, Train Loss: 0.054710, Train Error: 0.177292, Test Error: 0.175055\n",
      "Epoch: 16, Train Loss: 0.054551, Train Error: 0.177081, Test Error: 0.174942\n",
      "Epoch: 17, Train Loss: 0.054387, Train Error: 0.176855, Test Error: 0.174821\n",
      "Epoch: 18, Train Loss: 0.054231, Train Error: 0.176628, Test Error: 0.174679\n",
      "Epoch: 19, Train Loss: 0.054076, Train Error: 0.176402, Test Error: 0.174547\n",
      "Epoch: 20, Train Loss: 0.053920, Train Error: 0.176166, Test Error: 0.174446\n",
      "Epoch: 21, Train Loss: 0.053739, Train Error: 0.175891, Test Error: 0.174352\n",
      "Epoch: 22, Train Loss: 0.053557, Train Error: 0.175603, Test Error: 0.174226\n",
      "Epoch: 23, Train Loss: 0.053366, Train Error: 0.175287, Test Error: 0.174094\n",
      "Epoch: 24, Train Loss: 0.053162, Train Error: 0.174942, Test Error: 0.173943\n",
      "Epoch: 25, Train Loss: 0.052945, Train Error: 0.174564, Test Error: 0.173788\n",
      "Epoch: 26, Train Loss: 0.052718, Train Error: 0.174155, Test Error: 0.173627\n",
      "Epoch: 27, Train Loss: 0.052478, Train Error: 0.173716, Test Error: 0.173486\n",
      "Epoch: 28, Train Loss: 0.052237, Train Error: 0.173265, Test Error: 0.173295\n",
      "Epoch: 29, Train Loss: 0.051982, Train Error: 0.172779, Test Error: 0.173019\n",
      "Epoch: 30, Train Loss: 0.051710, Train Error: 0.172249, Test Error: 0.172703\n",
      "Epoch: 31, Train Loss: 0.051415, Train Error: 0.171666, Test Error: 0.172449\n",
      "Epoch: 32, Train Loss: 0.051100, Train Error: 0.171042, Test Error: 0.172153\n",
      "Epoch: 33, Train Loss: 0.050760, Train Error: 0.170355, Test Error: 0.171848\n",
      "Epoch: 34, Train Loss: 0.050354, Train Error: 0.169571, Test Error: 0.171416\n",
      "Epoch: 35, Train Loss: 0.049945, Train Error: 0.168755, Test Error: 0.170871\n",
      "Epoch: 36, Train Loss: 0.049525, Train Error: 0.167904, Test Error: 0.170263\n",
      "Epoch: 37, Train Loss: 0.049098, Train Error: 0.167024, Test Error: 0.169624\n",
      "Epoch: 38, Train Loss: 0.048652, Train Error: 0.166086, Test Error: 0.168941\n",
      "Epoch: 39, Train Loss: 0.048211, Train Error: 0.165147, Test Error: 0.168346\n",
      "Epoch: 40, Train Loss: 0.047767, Train Error: 0.164203, Test Error: 0.167693\n",
      "Epoch: 41, Train Loss: 0.047336, Train Error: 0.163262, Test Error: 0.167057\n",
      "Epoch: 42, Train Loss: 0.046927, Train Error: 0.162353, Test Error: 0.166407\n",
      "Epoch: 43, Train Loss: 0.046523, Train Error: 0.161453, Test Error: 0.165813\n",
      "Epoch: 44, Train Loss: 0.046124, Train Error: 0.160577, Test Error: 0.165287\n",
      "Epoch: 45, Train Loss: 0.045752, Train Error: 0.159743, Test Error: 0.164791\n",
      "Epoch: 46, Train Loss: 0.045372, Train Error: 0.158888, Test Error: 0.164230\n",
      "Epoch: 47, Train Loss: 0.045008, Train Error: 0.158071, Test Error: 0.163714\n",
      "Epoch: 48, Train Loss: 0.044674, Train Error: 0.157325, Test Error: 0.163219\n",
      "Epoch: 49, Train Loss: 0.044348, Train Error: 0.156611, Test Error: 0.162752\n",
      "Epoch: 50, Train Loss: 0.044028, Train Error: 0.155895, Test Error: 0.162230\n",
      "Epoch: 51, Train Loss: 0.043764, Train Error: 0.155326, Test Error: 0.161868\n",
      "Epoch: 52, Train Loss: 0.043430, Train Error: 0.154625, Test Error: 0.161310\n",
      "Epoch: 53, Train Loss: 0.043212, Train Error: 0.154187, Test Error: 0.160770\n",
      "Epoch: 54, Train Loss: 0.042933, Train Error: 0.153590, Test Error: 0.160132\n",
      "Epoch: 55, Train Loss: 0.042714, Train Error: 0.153085, Test Error: 0.159704\n",
      "Epoch: 56, Train Loss: 0.042330, Train Error: 0.152222, Test Error: 0.159248\n",
      "Epoch: 57, Train Loss: 0.042060, Train Error: 0.151628, Test Error: 0.158868\n",
      "Epoch: 58, Train Loss: 0.041719, Train Error: 0.150850, Test Error: 0.158445\n",
      "Epoch: 59, Train Loss: 0.041491, Train Error: 0.150332, Test Error: 0.158021\n",
      "Epoch: 60, Train Loss: 0.041169, Train Error: 0.149615, Test Error: 0.157740\n",
      "Epoch: 61, Train Loss: 0.040921, Train Error: 0.149075, Test Error: 0.157294\n",
      "Epoch: 62, Train Loss: 0.040622, Train Error: 0.148402, Test Error: 0.156985\n",
      "Epoch: 63, Train Loss: 0.040393, Train Error: 0.147886, Test Error: 0.156590\n",
      "Epoch: 64, Train Loss: 0.040133, Train Error: 0.147277, Test Error: 0.156225\n",
      "Epoch: 65, Train Loss: 0.039933, Train Error: 0.146810, Test Error: 0.155846\n",
      "Epoch: 66, Train Loss: 0.039687, Train Error: 0.146246, Test Error: 0.155399\n",
      "Epoch: 67, Train Loss: 0.039479, Train Error: 0.145763, Test Error: 0.155124\n",
      "Epoch: 68, Train Loss: 0.039264, Train Error: 0.145248, Test Error: 0.154636\n",
      "Epoch: 69, Train Loss: 0.039054, Train Error: 0.144777, Test Error: 0.154465\n",
      "Epoch: 70, Train Loss: 0.038830, Train Error: 0.144254, Test Error: 0.154165\n",
      "Epoch: 71, Train Loss: 0.038612, Train Error: 0.143787, Test Error: 0.154053\n",
      "Epoch: 72, Train Loss: 0.038409, Train Error: 0.143320, Test Error: 0.153639\n",
      "Epoch: 73, Train Loss: 0.038216, Train Error: 0.142897, Test Error: 0.153460\n",
      "Epoch: 74, Train Loss: 0.038031, Train Error: 0.142486, Test Error: 0.153039\n",
      "Epoch: 75, Train Loss: 0.037875, Train Error: 0.142146, Test Error: 0.152836\n",
      "Epoch: 76, Train Loss: 0.037690, Train Error: 0.141756, Test Error: 0.152509\n",
      "Epoch: 77, Train Loss: 0.037566, Train Error: 0.141479, Test Error: 0.152441\n",
      "Epoch: 78, Train Loss: 0.037391, Train Error: 0.141111, Test Error: 0.152273\n",
      "Epoch: 79, Train Loss: 0.037282, Train Error: 0.140868, Test Error: 0.152096\n",
      "Epoch: 80, Train Loss: 0.037102, Train Error: 0.140481, Test Error: 0.151981\n",
      "Epoch: 81, Train Loss: 0.037008, Train Error: 0.140268, Test Error: 0.151755\n",
      "Epoch: 82, Train Loss: 0.036818, Train Error: 0.139853, Test Error: 0.151565\n",
      "Epoch: 83, Train Loss: 0.036698, Train Error: 0.139577, Test Error: 0.151325\n",
      "Epoch: 84, Train Loss: 0.036518, Train Error: 0.139182, Test Error: 0.151128\n",
      "Epoch: 85, Train Loss: 0.036393, Train Error: 0.138896, Test Error: 0.150894\n",
      "Epoch: 86, Train Loss: 0.036218, Train Error: 0.138516, Test Error: 0.150635\n",
      "Epoch: 87, Train Loss: 0.036091, Train Error: 0.138222, Test Error: 0.150449\n",
      "Epoch: 88, Train Loss: 0.035915, Train Error: 0.137832, Test Error: 0.150210\n",
      "Epoch: 89, Train Loss: 0.035781, Train Error: 0.137522, Test Error: 0.150058\n",
      "Epoch: 90, Train Loss: 0.035626, Train Error: 0.137182, Test Error: 0.149821\n",
      "Epoch: 91, Train Loss: 0.035494, Train Error: 0.136884, Test Error: 0.149763\n",
      "Epoch: 92, Train Loss: 0.035348, Train Error: 0.136572, Test Error: 0.149554\n",
      "Epoch: 93, Train Loss: 0.035229, Train Error: 0.136315, Test Error: 0.149563\n",
      "Epoch: 94, Train Loss: 0.035080, Train Error: 0.135994, Test Error: 0.149365\n",
      "Epoch: 95, Train Loss: 0.034963, Train Error: 0.135748, Test Error: 0.149363\n",
      "Epoch: 96, Train Loss: 0.034825, Train Error: 0.135430, Test Error: 0.149121\n",
      "Epoch: 97, Train Loss: 0.034720, Train Error: 0.135198, Test Error: 0.149223\n",
      "Epoch: 98, Train Loss: 0.034592, Train Error: 0.134907, Test Error: 0.148992\n",
      "Epoch: 99, Train Loss: 0.034492, Train Error: 0.134693, Test Error: 0.149116\n",
      "Epoch: 100, Train Loss: 0.034368, Train Error: 0.134404, Test Error: 0.148913\n",
      "Epoch: 101, Train Loss: 0.034285, Train Error: 0.134234, Test Error: 0.148980\n",
      "Epoch: 102, Train Loss: 0.034170, Train Error: 0.133963, Test Error: 0.148905\n",
      "Epoch: 103, Train Loss: 0.034112, Train Error: 0.133860, Test Error: 0.148972\n",
      "Epoch: 104, Train Loss: 0.033996, Train Error: 0.133602, Test Error: 0.148805\n",
      "Epoch: 105, Train Loss: 0.033924, Train Error: 0.133448, Test Error: 0.148886\n",
      "Epoch: 106, Train Loss: 0.033793, Train Error: 0.133145, Test Error: 0.148688\n",
      "Epoch: 107, Train Loss: 0.033708, Train Error: 0.132946, Test Error: 0.148710\n",
      "Epoch: 108, Train Loss: 0.033604, Train Error: 0.132693, Test Error: 0.148576\n",
      "Epoch: 109, Train Loss: 0.033529, Train Error: 0.132522, Test Error: 0.148576\n",
      "Epoch: 110, Train Loss: 0.033422, Train Error: 0.132256, Test Error: 0.148506\n",
      "Epoch: 111, Train Loss: 0.033358, Train Error: 0.132113, Test Error: 0.148531\n",
      "Epoch: 112, Train Loss: 0.033268, Train Error: 0.131870, Test Error: 0.148504\n",
      "Epoch: 113, Train Loss: 0.033228, Train Error: 0.131794, Test Error: 0.148583\n",
      "Epoch: 114, Train Loss: 0.033149, Train Error: 0.131582, Test Error: 0.148488\n",
      "Epoch: 115, Train Loss: 0.033101, Train Error: 0.131476, Test Error: 0.148676\n",
      "Epoch: 116, Train Loss: 0.033034, Train Error: 0.131305, Test Error: 0.148671\n",
      "Epoch: 117, Train Loss: 0.032994, Train Error: 0.131219, Test Error: 0.148921\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=args.splits, random_state=42, shuffle=True)\n",
    "print(\"Torch: \")\n",
    "\n",
    "ks = [0.9, 0.7, 0.6, 0.5]\n",
    "\n",
    "best_model_fold_list = []\n",
    "data_fold_list = []\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(X):\n",
    "\n",
    "    print(f\"----- Fold {i} -----\")\n",
    "\n",
    "    model = GSRNet(ks, args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = X[\n",
    "        train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "    data_fold_list.append((subjects_adj, test_adj, subjects_ground_truth, test_ground_truth))\n",
    "\n",
    "\n",
    "    ##################\n",
    "    # subjects_adj = subjects_adj[:1]\n",
    "    # subjects_ground_truth = subjects_ground_truth[:1]\n",
    "    ##################\n",
    "\n",
    "    return_model = train(model, optimizer, subjects_adj, subjects_ground_truth, args, test_adj, test_ground_truth)\n",
    "    test(return_model, test_adj, test_ground_truth, args)\n",
    "    best_model_fold_list.append(return_model)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "def evaluate(pred_matrices, gt_matrices):\n",
    "\n",
    "    num_test_samples = gt_matrices.shape[0]\n",
    "\n",
    "    # Initialize lists to store MAEs for each centrality measure\n",
    "    mae_bc = []\n",
    "    mae_ec = []\n",
    "    mae_pc = []\n",
    "\n",
    "    # # Iterate over each test sample\n",
    "    # for i in range(num_test_samples):\n",
    "    #     # Convert adjacency matrices to NetworkX graphs\n",
    "    #     pred_graph = nx.from_numpy_array(pred_matrices[i], edge_attr=\"weight\")\n",
    "    #     gt_graph = nx.from_numpy_array(gt_matrices[i], edge_attr=\"weight\")\n",
    "\n",
    "    #     # Compute centrality measures\n",
    "    #     pred_bc = nx.betweenness_centrality(pred_graph, weight=\"weight\")\n",
    "    #     pred_ec = nx.eigenvector_centrality(pred_graph, weight=\"weight\")\n",
    "    #     pred_pc = nx.pagerank(pred_graph, weight=\"weight\")\n",
    "\n",
    "    #     gt_bc = nx.betweenness_centrality(gt_graph, weight=\"weight\")\n",
    "    #     gt_ec = nx.eigenvector_centrality(gt_graph, weight=\"weight\")\n",
    "    #     gt_pc = nx.pagerank(gt_graph, weight=\"weight\")\n",
    "\n",
    "    #     # Convert centrality dictionaries to lists\n",
    "    #     pred_bc_values = list(pred_bc.values())\n",
    "    #     pred_ec_values = list(pred_ec.values())\n",
    "    #     pred_pc_values = list(pred_pc.values())\n",
    "\n",
    "    #     gt_bc_values = list(gt_bc.values())\n",
    "    #     gt_ec_values = list(gt_ec.values())\n",
    "    #     gt_pc_values = list(gt_pc.values())\n",
    "\n",
    "    #     # Compute MAEs\n",
    "    #     mae_bc.append(mean_absolute_error(pred_bc_values, gt_bc_values))\n",
    "    #     mae_ec.append(mean_absolute_error(pred_ec_values, gt_ec_values))\n",
    "    #     mae_pc.append(mean_absolute_error(pred_pc_values, gt_pc_values))\n",
    "\n",
    "    # # Compute average MAEs\n",
    "    # avg_mae_bc = sum(mae_bc) / len(mae_bc)\n",
    "    # avg_mae_ec = sum(mae_ec) / len(mae_ec)\n",
    "    # avg_mae_pc = sum(mae_pc) / len(mae_pc)\n",
    "\n",
    "    # vectorize and flatten\n",
    "    pred_1d = MatrixVectorizer.vectorize(pred_matrices).flatten()\n",
    "    gt_1d = MatrixVectorizer.vectorize(gt_matrices).flatten()\n",
    "\n",
    "    mae = mean_absolute_error(pred_1d, gt_1d)\n",
    "    pcc = pearsonr(pred_1d, gt_1d)[0]\n",
    "    js_dis = jensenshannon(pred_1d, gt_1d)\n",
    "\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"PCC: \", pcc)\n",
    "    print(\"Jensen-Shannon Distance: \", js_dis)\n",
    "    # print(\"Average MAE betweenness centrality:\", avg_mae_bc)\n",
    "    # print(\"Average MAE eigenvector centrality:\", avg_mae_ec)\n",
    "    # print(\"Average MAE PageRank centrality:\", avg_mae_pc)\n",
    "    # return mae, pcc, js_dis, avg_mae_bc, avg_mae_ec, avg_mae_pc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.14835803751452897\n",
      "PCC:  0.5928507311234573\n",
      "Jensen-Shannon Distance:  0.29957283150860553\n",
      "MAE:  0.1578448729087319\n",
      "PCC:  0.5642614149988106\n",
      "Jensen-Shannon Distance:  0.3078476609803951\n",
      "MAE:  0.15251106211067725\n",
      "PCC:  0.586215228686752\n",
      "Jensen-Shannon Distance:  0.29401755777854227\n"
     ]
    }
   ],
   "source": [
    "for i in range(args.splits):\n",
    "    _, test_adjs, _, gt_matrices = data_fold_list[i]\n",
    "    model = best_model_fold_list[i]\n",
    "    model.eval()\n",
    "    pred_matrices = np.zeros(gt_matrices.shape)\n",
    "    with torch.no_grad():\n",
    "        for j, test_adj in enumerate(test_adjs):\n",
    "            pred_matrices[j], _, _, _ = model(torch.from_numpy(test_adj))\n",
    "    evaluate(pred_matrices, gt_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.097118, Train Error: 0.222979\n",
      "Epoch: 1, Train Loss: 0.070837, Train Error: 0.195681\n",
      "Epoch: 2, Train Loss: 0.066570, Train Error: 0.191245\n",
      "Epoch: 3, Train Loss: 0.064896, Train Error: 0.189831\n",
      "Epoch: 4, Train Loss: 0.064007, Train Error: 0.189172\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 110\n",
    "\n",
    "final_model = GSRNet(ks, args).to(device)\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=args.lr)\n",
    "\n",
    "# subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = X[\n",
    "#     train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "# data_fold_list.append((subjects_adj, test_adj, subjects_ground_truth, test_ground_truth))\n",
    "\n",
    "\n",
    "##################\n",
    "# subjects_adj = subjects_adj[:1]\n",
    "# subjects_ground_truth = subjects_ground_truth[:1]\n",
    "##################\n",
    "\n",
    "final_model = train(final_model, optimizer, X, Y, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_list = []\n",
    "for i in range(A_LR_test_matrix.shape[0]):\n",
    "    output_pred = final_model(A_LR_test_matrix[i])\n",
    "    output_pred = MatrixVectorizer.vectorize(output_pred).tolist()\n",
    "    output_pred_list += output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"ID\": [i+1 for i in range(len(output_pred_list))],\n",
    "    \"Predicted\": output_pred_list\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
