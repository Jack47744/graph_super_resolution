{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MatrixVectorizer import *\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Check for CUDA (GPU support) and set device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # For multi-GPU setups\n",
    "    # Additional settings for ensuring reproducibility on CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_LR_train = pd.read_csv(\"../data/lr_train.csv\")\n",
    "# A_HR_train = pd.read_csv(\"../data/hr_train.csv\")\n",
    "# A_LR_test = pd.read_csv(\"../data/lr_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_size = 160\n",
    "HR_size = 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatrixVectorizer = MatrixVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_subject = A_LR_train.shape[0]\n",
    "# A_LR_train_matrix = np.zeros((num_subject, LR_size, LR_size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "# for i in range(num_subject):\n",
    "#     A_LR_train_matrix[i] = MatrixVectorizer.anti_vectorize(A_LR_train.iloc[i], LR_size) # torch.from_numpy(MatrixVectorizer.anti_vectorize(A_LR_train.iloc[i], LR_size))\n",
    "\n",
    "# A_HR_train_matrix = np.zeros((num_subject, HR_size, HR_size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "# for i in range(num_subject):\n",
    "#     A_HR_train_matrix[i] = MatrixVectorizer.anti_vectorize(A_HR_train.iloc[i], HR_size) \n",
    "\n",
    "# num_subject = len(A_LR_test)\n",
    "# A_LR_test_matrix = np.zeros((num_subject, LR_size, LR_size)) #torch.zeros((num_subject, LR_size, LR_size))\n",
    "# for i in range(num_subject):\n",
    "#     A_LR_test_matrix[i] = MatrixVectorizer.anti_vectorize(A_LR_test.iloc[i], LR_size) \n",
    "\n",
    "# np.save('A_LR_train_matrix.npy', A_LR_train_matrix)\n",
    "# np.save('A_HR_train_matrix.npy', A_HR_train_matrix)\n",
    "# np.save('A_LR_test_matrix.npy', A_LR_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 160, 160)\n",
      "(167, 268, 268)\n",
      "(112, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "A_LR_train_matrix = np.load('A_LR_train_matrix.npy')\n",
    "A_HR_train_matrix = np.load('A_HR_train_matrix.npy')\n",
    "A_LR_test_matrix = np.load(\"A_LR_test_matrix.npy\")\n",
    "\n",
    "print(A_LR_train_matrix.shape)\n",
    "print(A_HR_train_matrix.shape)\n",
    "print(A_LR_test_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=200, lr=0.0001, splits=3, lmbda=16, lr_dim=160, hr_dim=268, hidden_dim=280, padding=26)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function of Graph Super-Resolution Network (GSR-Net) framework \n",
    "   for predicting high-resolution brain connectomes from low-resolution connectomes. \n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    This file contains the implementation of the training and testing process of our GSR-Net model.\n",
    "        train(model, optimizer, subjects_adj, subjects_ground_truth, args)\n",
    "\n",
    "                Inputs:\n",
    "                        model:        constructor of our GSR-Net model:  model = GSRNet(ks,args)\n",
    "                                      ks:   array that stores reduction rates of nodes in Graph U-Net pooling layers\n",
    "                                      args: parsed command line arguments\n",
    "\n",
    "                        optimizer:    constructor of our model's optimizer (borrowed from PyTorch)  \n",
    "\n",
    "                        subjects_adj: (n × l x l) tensor stacking LR connectivity matrices of all training subjects\n",
    "                                       n: the total number of subjects\n",
    "                                       l: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        subjects_ground_truth: (n × h x h) tensor stacking LR connectivity matrices of all training subjects\n",
    "                                                n: the total number of subjects\n",
    "                                                h: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        args:          parsed command line arguments, to learn more about the arguments run: \n",
    "                                       python demo.py --help\n",
    "                Output:\n",
    "                        for each epoch, prints out the mean training MSE error\n",
    "\n",
    "\n",
    "            \n",
    "        test(model, test_adj,test_ground_truth,args)\n",
    "\n",
    "                Inputs:\n",
    "                        test_adj:      (n × l x l) tensor stacking LR connectivity matrices of all testing subjects\n",
    "                                        n: the total number of subjects\n",
    "                                        l: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        test_ground_truth:      (n × h x h) tensor stacking LR connectivity matrices of all testing subjects\n",
    "                                                 n: the total number of subjects\n",
    "                                                 h: the dimensions of the LR connectivity matrices\n",
    "\n",
    "                        see train method above for model and args.\n",
    "\n",
    "                Outputs:\n",
    "                        for each epoch, prints out the mean testing MSE error\n",
    "\n",
    "\n",
    "    To evaluate our framework we used 5-fold cross-validation strategy.\n",
    "\n",
    "    ---------------------------------------------------------------------\n",
    "    Copyright 2020 Megi Isallari, Istanbul Technical University.\n",
    "    All rights reserved.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from preprocessing import *\n",
    "from model import *\n",
    "from train import *\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GSR-Net')\n",
    "parser.add_argument('--epochs', type=int, default=epochs, metavar='no_epochs',\n",
    "                help='number of episode to train ')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, metavar='lr',\n",
    "                help='learning rate (default: 0.0001 using Adam Optimizer)')\n",
    "parser.add_argument('--splits', type=int, default=3, metavar='n_splits',\n",
    "                help='no of cross validation folds')\n",
    "parser.add_argument('--lmbda', type=int, default=16, metavar='L',\n",
    "                help='self-reconstruction error hyperparameter')\n",
    "parser.add_argument('--lr_dim', type=int, default=LR_size, metavar='N',\n",
    "                help='adjacency matrix input dimensions')\n",
    "parser.add_argument('--hr_dim', type=int, default=HR_size, metavar='N',\n",
    "                help='super-resolved adjacency matrix output dimensions')\n",
    "parser.add_argument('--hidden_dim', type=int, default=280, metavar='N',\n",
    "                help='hidden GraphConvolutional layer dimensions')\n",
    "parser.add_argument('--padding', type=int, default=26, metavar='padding',\n",
    "                help='dimensions of padding')\n",
    "\n",
    "# Create an empty Namespace to hold the default arguments\n",
    "args = parser.parse_args([]) \n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 160, 160)\n",
      "(167, 268, 268)\n"
     ]
    }
   ],
   "source": [
    "# SIMULATING THE DATA: EDIT TO ENTER YOUR OWN DATA\n",
    "X = A_LR_train_matrix #np.random.normal(0, 0.5, (167, 160, 160))\n",
    "Y = A_HR_train_matrix #np.random.normal(0, 0.5, (167, 288, 288))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 1 -----\n",
      "Epoch: 0, Train Loss: 1.101811, Train Error: 0.232926, Test Error: 0.199106\n",
      "Epoch: 1, Train Loss: 1.070682, Train Error: 0.201881, Test Error: 0.187819\n",
      "Epoch: 2, Train Loss: 1.064509, Train Error: 0.194951, Test Error: 0.183715\n",
      "Epoch: 3, Train Loss: 1.061893, Train Error: 0.192073, Test Error: 0.181875\n",
      "Epoch: 4, Train Loss: 1.060546, Train Error: 0.190568, Test Error: 0.180831\n",
      "Epoch: 5, Train Loss: 1.059662, Train Error: 0.189577, Test Error: 0.180147\n",
      "Epoch: 6, Train Loss: 1.059040, Train Error: 0.188870, Test Error: 0.179723\n",
      "Epoch: 7, Train Loss: 1.058599, Train Error: 0.188356, Test Error: 0.179480\n",
      "Epoch: 8, Train Loss: 1.058276, Train Error: 0.187989, Test Error: 0.179320\n",
      "Epoch: 9, Train Loss: 1.058019, Train Error: 0.187684, Test Error: 0.179111\n",
      "Epoch: 10, Train Loss: 1.057800, Train Error: 0.187390, Test Error: 0.178789\n",
      "Epoch: 11, Train Loss: 1.057560, Train Error: 0.187057, Test Error: 0.178568\n",
      "Epoch: 12, Train Loss: 1.057335, Train Error: 0.186719, Test Error: 0.178396\n",
      "Epoch: 13, Train Loss: 1.057129, Train Error: 0.186458, Test Error: 0.178195\n",
      "Epoch: 14, Train Loss: 1.056883, Train Error: 0.186086, Test Error: 0.177921\n",
      "Epoch: 15, Train Loss: 1.056629, Train Error: 0.185689, Test Error: 0.177613\n",
      "Epoch: 16, Train Loss: 1.056347, Train Error: 0.185232, Test Error: 0.177264\n",
      "Epoch: 17, Train Loss: 1.055965, Train Error: 0.184650, Test Error: 0.176793\n",
      "Epoch: 18, Train Loss: 1.055503, Train Error: 0.183926, Test Error: 0.176210\n",
      "Epoch: 19, Train Loss: 1.054903, Train Error: 0.182966, Test Error: 0.175412\n",
      "Epoch: 20, Train Loss: 1.054141, Train Error: 0.181733, Test Error: 0.174339\n",
      "Epoch: 21, Train Loss: 1.053143, Train Error: 0.180150, Test Error: 0.172905\n",
      "Epoch: 22, Train Loss: 1.051915, Train Error: 0.178233, Test Error: 0.171275\n",
      "Epoch: 23, Train Loss: 1.050541, Train Error: 0.176128, Test Error: 0.169639\n",
      "Epoch: 24, Train Loss: 1.049304, Train Error: 0.174272, Test Error: 0.168381\n",
      "Epoch: 25, Train Loss: 1.048320, Train Error: 0.172780, Test Error: 0.167545\n",
      "Epoch: 26, Train Loss: 1.047584, Train Error: 0.171652, Test Error: 0.167035\n",
      "Epoch: 27, Train Loss: 1.046967, Train Error: 0.170666, Test Error: 0.166540\n",
      "Epoch: 28, Train Loss: 1.046427, Train Error: 0.169766, Test Error: 0.166173\n",
      "Epoch: 29, Train Loss: 1.045938, Train Error: 0.168895, Test Error: 0.165867\n",
      "Epoch: 30, Train Loss: 1.045466, Train Error: 0.168031, Test Error: 0.165459\n",
      "Epoch: 31, Train Loss: 1.045013, Train Error: 0.167184, Test Error: 0.165074\n",
      "Epoch: 32, Train Loss: 1.044572, Train Error: 0.166333, Test Error: 0.164669\n",
      "Epoch: 33, Train Loss: 1.044119, Train Error: 0.165436, Test Error: 0.164317\n",
      "Epoch: 34, Train Loss: 1.043699, Train Error: 0.164583, Test Error: 0.163936\n",
      "Epoch: 35, Train Loss: 1.043288, Train Error: 0.163736, Test Error: 0.163459\n",
      "Epoch: 36, Train Loss: 1.042893, Train Error: 0.162899, Test Error: 0.162935\n",
      "Epoch: 37, Train Loss: 1.042489, Train Error: 0.162083, Test Error: 0.162447\n",
      "Epoch: 38, Train Loss: 1.042067, Train Error: 0.161199, Test Error: 0.161954\n",
      "Epoch: 39, Train Loss: 1.041641, Train Error: 0.160279, Test Error: 0.161506\n",
      "Epoch: 40, Train Loss: 1.041259, Train Error: 0.159421, Test Error: 0.161027\n",
      "Epoch: 41, Train Loss: 1.040879, Train Error: 0.158582, Test Error: 0.160521\n",
      "Epoch: 42, Train Loss: 1.040541, Train Error: 0.157799, Test Error: 0.160107\n",
      "Epoch: 43, Train Loss: 1.040218, Train Error: 0.157055, Test Error: 0.159662\n",
      "Epoch: 44, Train Loss: 1.039942, Train Error: 0.156384, Test Error: 0.159341\n",
      "Epoch: 45, Train Loss: 1.039650, Train Error: 0.155693, Test Error: 0.158971\n",
      "Epoch: 46, Train Loss: 1.039351, Train Error: 0.154969, Test Error: 0.158654\n",
      "Epoch: 47, Train Loss: 1.039060, Train Error: 0.154292, Test Error: 0.158278\n",
      "Epoch: 48, Train Loss: 1.038779, Train Error: 0.153622, Test Error: 0.157927\n",
      "Epoch: 49, Train Loss: 1.038500, Train Error: 0.152939, Test Error: 0.157543\n",
      "Epoch: 50, Train Loss: 1.038248, Train Error: 0.152329, Test Error: 0.157166\n",
      "Epoch: 51, Train Loss: 1.038004, Train Error: 0.151749, Test Error: 0.156787\n",
      "Epoch: 52, Train Loss: 1.037780, Train Error: 0.151226, Test Error: 0.156440\n",
      "Epoch: 53, Train Loss: 1.037536, Train Error: 0.150658, Test Error: 0.156102\n",
      "Epoch: 54, Train Loss: 1.037309, Train Error: 0.150142, Test Error: 0.155817\n",
      "Epoch: 55, Train Loss: 1.037095, Train Error: 0.149640, Test Error: 0.155583\n",
      "Epoch: 56, Train Loss: 1.036906, Train Error: 0.149206, Test Error: 0.155365\n",
      "Epoch: 57, Train Loss: 1.036714, Train Error: 0.148749, Test Error: 0.155198\n",
      "Epoch: 58, Train Loss: 1.036531, Train Error: 0.148330, Test Error: 0.155009\n",
      "Epoch: 59, Train Loss: 1.036352, Train Error: 0.147891, Test Error: 0.154844\n",
      "Epoch: 60, Train Loss: 1.036214, Train Error: 0.147565, Test Error: 0.154715\n",
      "Epoch: 61, Train Loss: 1.036088, Train Error: 0.147213, Test Error: 0.154523\n",
      "Epoch: 62, Train Loss: 1.035915, Train Error: 0.146784, Test Error: 0.154349\n",
      "Epoch: 63, Train Loss: 1.035766, Train Error: 0.146412, Test Error: 0.154112\n",
      "Epoch: 64, Train Loss: 1.035632, Train Error: 0.146065, Test Error: 0.153862\n",
      "Epoch: 65, Train Loss: 1.035476, Train Error: 0.145679, Test Error: 0.153650\n",
      "Epoch: 66, Train Loss: 1.035344, Train Error: 0.145324, Test Error: 0.153534\n",
      "Epoch: 67, Train Loss: 1.035194, Train Error: 0.144936, Test Error: 0.153340\n",
      "Epoch: 68, Train Loss: 1.035047, Train Error: 0.144533, Test Error: 0.153252\n",
      "Epoch: 69, Train Loss: 1.034931, Train Error: 0.144275, Test Error: 0.153068\n",
      "Epoch: 70, Train Loss: 1.034799, Train Error: 0.143958, Test Error: 0.152922\n",
      "Epoch: 71, Train Loss: 1.034647, Train Error: 0.143545, Test Error: 0.152817\n",
      "Epoch: 72, Train Loss: 1.034518, Train Error: 0.143213, Test Error: 0.152740\n",
      "Epoch: 73, Train Loss: 1.034400, Train Error: 0.142908, Test Error: 0.152508\n",
      "Epoch: 74, Train Loss: 1.034300, Train Error: 0.142669, Test Error: 0.152458\n",
      "Epoch: 75, Train Loss: 1.034167, Train Error: 0.142301, Test Error: 0.152326\n",
      "Epoch: 76, Train Loss: 1.034092, Train Error: 0.142107, Test Error: 0.152215\n",
      "Epoch: 77, Train Loss: 1.033966, Train Error: 0.141762, Test Error: 0.152132\n",
      "Epoch: 78, Train Loss: 1.033866, Train Error: 0.141492, Test Error: 0.152117\n",
      "Epoch: 79, Train Loss: 1.033752, Train Error: 0.141177, Test Error: 0.152000\n",
      "Epoch: 80, Train Loss: 1.033646, Train Error: 0.140905, Test Error: 0.151928\n",
      "Epoch: 81, Train Loss: 1.033554, Train Error: 0.140666, Test Error: 0.151757\n",
      "Epoch: 82, Train Loss: 1.033453, Train Error: 0.140400, Test Error: 0.151621\n",
      "Epoch: 83, Train Loss: 1.033367, Train Error: 0.140159, Test Error: 0.151417\n",
      "Epoch: 84, Train Loss: 1.033280, Train Error: 0.139907, Test Error: 0.151399\n",
      "Epoch: 85, Train Loss: 1.033176, Train Error: 0.139629, Test Error: 0.151221\n",
      "Epoch: 86, Train Loss: 1.033084, Train Error: 0.139360, Test Error: 0.151124\n",
      "Epoch: 87, Train Loss: 1.032988, Train Error: 0.139127, Test Error: 0.150997\n",
      "Epoch: 88, Train Loss: 1.032899, Train Error: 0.138878, Test Error: 0.150913\n",
      "Epoch: 89, Train Loss: 1.032813, Train Error: 0.138683, Test Error: 0.150719\n",
      "Epoch: 90, Train Loss: 1.032747, Train Error: 0.138499, Test Error: 0.150743\n",
      "Epoch: 91, Train Loss: 1.032641, Train Error: 0.138260, Test Error: 0.150770\n",
      "Epoch: 92, Train Loss: 1.032544, Train Error: 0.138038, Test Error: 0.150586\n",
      "Epoch: 93, Train Loss: 1.032419, Train Error: 0.137722, Test Error: 0.150530\n",
      "Epoch: 94, Train Loss: 1.032329, Train Error: 0.137500, Test Error: 0.150375\n",
      "Epoch: 95, Train Loss: 1.032229, Train Error: 0.137261, Test Error: 0.150425\n",
      "Epoch: 96, Train Loss: 1.032141, Train Error: 0.137049, Test Error: 0.150291\n",
      "Epoch: 97, Train Loss: 1.032063, Train Error: 0.136875, Test Error: 0.150015\n",
      "Epoch: 98, Train Loss: 1.031965, Train Error: 0.136612, Test Error: 0.149875\n",
      "Epoch: 99, Train Loss: 1.031887, Train Error: 0.136454, Test Error: 0.149790\n",
      "Epoch: 100, Train Loss: 1.031807, Train Error: 0.136224, Test Error: 0.149716\n",
      "Epoch: 101, Train Loss: 1.031721, Train Error: 0.136051, Test Error: 0.149562\n",
      "Epoch: 102, Train Loss: 1.031611, Train Error: 0.135801, Test Error: 0.149319\n",
      "Epoch: 103, Train Loss: 1.031514, Train Error: 0.135603, Test Error: 0.149348\n",
      "Epoch: 104, Train Loss: 1.031418, Train Error: 0.135403, Test Error: 0.149195\n",
      "Epoch: 105, Train Loss: 1.031309, Train Error: 0.135200, Test Error: 0.149026\n",
      "Epoch: 106, Train Loss: 1.031207, Train Error: 0.134981, Test Error: 0.149117\n",
      "Epoch: 107, Train Loss: 1.031118, Train Error: 0.134813, Test Error: 0.149053\n",
      "Epoch: 108, Train Loss: 1.031025, Train Error: 0.134596, Test Error: 0.149050\n",
      "Epoch: 109, Train Loss: 1.030993, Train Error: 0.134561, Test Error: 0.148974\n",
      "Epoch: 110, Train Loss: 1.030853, Train Error: 0.134259, Test Error: 0.148752\n",
      "Epoch: 111, Train Loss: 1.030747, Train Error: 0.134075, Test Error: 0.148802\n",
      "Epoch: 112, Train Loss: 1.030643, Train Error: 0.133841, Test Error: 0.148767\n",
      "Epoch: 113, Train Loss: 1.030561, Train Error: 0.133661, Test Error: 0.148648\n",
      "Epoch: 114, Train Loss: 1.030469, Train Error: 0.133460, Test Error: 0.148507\n",
      "Epoch: 115, Train Loss: 1.030396, Train Error: 0.133326, Test Error: 0.148479\n",
      "Epoch: 116, Train Loss: 1.030307, Train Error: 0.133114, Test Error: 0.148357\n",
      "Epoch: 117, Train Loss: 1.030233, Train Error: 0.132977, Test Error: 0.148458\n",
      "Epoch: 118, Train Loss: 1.030157, Train Error: 0.132812, Test Error: 0.148431\n",
      "Epoch: 119, Train Loss: 1.030070, Train Error: 0.132635, Test Error: 0.148408\n",
      "Val Error: 0.148492\n",
      "----- Fold 2 -----\n",
      "Epoch: 0, Train Loss: 1.101972, Train Error: 0.233453, Test Error: 0.208121\n",
      "Epoch: 1, Train Loss: 1.069060, Train Error: 0.198606, Test Error: 0.193389\n",
      "Epoch: 2, Train Loss: 1.061481, Train Error: 0.189214, Test Error: 0.187851\n",
      "Epoch: 3, Train Loss: 1.058028, Train Error: 0.185059, Test Error: 0.185573\n",
      "Epoch: 4, Train Loss: 1.056428, Train Error: 0.183224, Test Error: 0.184364\n",
      "Epoch: 5, Train Loss: 1.055495, Train Error: 0.182116, Test Error: 0.183699\n",
      "Epoch: 6, Train Loss: 1.054956, Train Error: 0.181479, Test Error: 0.183337\n",
      "Epoch: 7, Train Loss: 1.054600, Train Error: 0.181029, Test Error: 0.183091\n",
      "Epoch: 8, Train Loss: 1.054337, Train Error: 0.180681, Test Error: 0.182861\n",
      "Epoch: 9, Train Loss: 1.054136, Train Error: 0.180402, Test Error: 0.182734\n",
      "Epoch: 10, Train Loss: 1.053956, Train Error: 0.180151, Test Error: 0.182637\n",
      "Epoch: 11, Train Loss: 1.053774, Train Error: 0.179901, Test Error: 0.182521\n",
      "Epoch: 12, Train Loss: 1.053611, Train Error: 0.179665, Test Error: 0.182426\n",
      "Epoch: 13, Train Loss: 1.053446, Train Error: 0.179426, Test Error: 0.182332\n",
      "Epoch: 14, Train Loss: 1.053292, Train Error: 0.179206, Test Error: 0.182213\n",
      "Epoch: 15, Train Loss: 1.053133, Train Error: 0.178970, Test Error: 0.182088\n",
      "Epoch: 16, Train Loss: 1.052952, Train Error: 0.178698, Test Error: 0.181936\n",
      "Epoch: 17, Train Loss: 1.052797, Train Error: 0.178466, Test Error: 0.181825\n",
      "Epoch: 18, Train Loss: 1.052622, Train Error: 0.178179, Test Error: 0.181706\n",
      "Epoch: 19, Train Loss: 1.052456, Train Error: 0.177899, Test Error: 0.181543\n",
      "Epoch: 20, Train Loss: 1.052279, Train Error: 0.177603, Test Error: 0.181424\n",
      "Epoch: 21, Train Loss: 1.052071, Train Error: 0.177260, Test Error: 0.181283\n",
      "Epoch: 22, Train Loss: 1.051819, Train Error: 0.176826, Test Error: 0.181146\n",
      "Epoch: 23, Train Loss: 1.051568, Train Error: 0.176364, Test Error: 0.181030\n",
      "Epoch: 24, Train Loss: 1.051304, Train Error: 0.175870, Test Error: 0.180846\n",
      "Epoch: 25, Train Loss: 1.051020, Train Error: 0.175336, Test Error: 0.180656\n",
      "Epoch: 26, Train Loss: 1.050726, Train Error: 0.174758, Test Error: 0.180431\n",
      "Epoch: 27, Train Loss: 1.050403, Train Error: 0.174118, Test Error: 0.180187\n",
      "Epoch: 28, Train Loss: 1.050046, Train Error: 0.173417, Test Error: 0.179904\n",
      "Epoch: 29, Train Loss: 1.049661, Train Error: 0.172660, Test Error: 0.179548\n",
      "Epoch: 30, Train Loss: 1.049225, Train Error: 0.171791, Test Error: 0.179083\n",
      "Epoch: 31, Train Loss: 1.048773, Train Error: 0.170886, Test Error: 0.178508\n",
      "Epoch: 32, Train Loss: 1.048273, Train Error: 0.169893, Test Error: 0.177857\n",
      "Epoch: 33, Train Loss: 1.047748, Train Error: 0.168854, Test Error: 0.177206\n",
      "Epoch: 34, Train Loss: 1.047182, Train Error: 0.167737, Test Error: 0.176432\n",
      "Epoch: 35, Train Loss: 1.046590, Train Error: 0.166549, Test Error: 0.175663\n",
      "Epoch: 36, Train Loss: 1.045969, Train Error: 0.165327, Test Error: 0.174841\n",
      "Epoch: 37, Train Loss: 1.045304, Train Error: 0.164011, Test Error: 0.173961\n",
      "Epoch: 38, Train Loss: 1.044613, Train Error: 0.162658, Test Error: 0.173039\n",
      "Epoch: 39, Train Loss: 1.043892, Train Error: 0.161255, Test Error: 0.171965\n",
      "Epoch: 40, Train Loss: 1.043124, Train Error: 0.159772, Test Error: 0.170917\n",
      "Epoch: 41, Train Loss: 1.042310, Train Error: 0.158213, Test Error: 0.169796\n",
      "Epoch: 42, Train Loss: 1.041482, Train Error: 0.156655, Test Error: 0.168611\n",
      "Epoch: 43, Train Loss: 1.040656, Train Error: 0.155111, Test Error: 0.167528\n",
      "Epoch: 44, Train Loss: 1.039838, Train Error: 0.153577, Test Error: 0.166576\n",
      "Epoch: 45, Train Loss: 1.039114, Train Error: 0.152212, Test Error: 0.165752\n",
      "Epoch: 46, Train Loss: 1.038491, Train Error: 0.151024, Test Error: 0.165122\n",
      "Epoch: 47, Train Loss: 1.037958, Train Error: 0.149946, Test Error: 0.164671\n",
      "Epoch: 48, Train Loss: 1.037506, Train Error: 0.148994, Test Error: 0.164194\n",
      "Epoch: 49, Train Loss: 1.037104, Train Error: 0.148111, Test Error: 0.163805\n",
      "Epoch: 50, Train Loss: 1.036742, Train Error: 0.147302, Test Error: 0.163385\n",
      "Epoch: 51, Train Loss: 1.036408, Train Error: 0.146536, Test Error: 0.163065\n",
      "Epoch: 52, Train Loss: 1.036082, Train Error: 0.145771, Test Error: 0.162727\n",
      "Epoch: 53, Train Loss: 1.035796, Train Error: 0.145096, Test Error: 0.162445\n",
      "Epoch: 54, Train Loss: 1.035513, Train Error: 0.144429, Test Error: 0.162166\n",
      "Epoch: 55, Train Loss: 1.035261, Train Error: 0.143803, Test Error: 0.161887\n",
      "Epoch: 56, Train Loss: 1.034992, Train Error: 0.143170, Test Error: 0.161624\n",
      "Epoch: 57, Train Loss: 1.034759, Train Error: 0.142609, Test Error: 0.161282\n",
      "Epoch: 58, Train Loss: 1.034502, Train Error: 0.141983, Test Error: 0.160966\n",
      "Epoch: 59, Train Loss: 1.034295, Train Error: 0.141479, Test Error: 0.160675\n",
      "Epoch: 60, Train Loss: 1.034069, Train Error: 0.140912, Test Error: 0.160389\n",
      "Epoch: 61, Train Loss: 1.033856, Train Error: 0.140381, Test Error: 0.160162\n",
      "Epoch: 62, Train Loss: 1.033676, Train Error: 0.139921, Test Error: 0.160024\n",
      "Epoch: 63, Train Loss: 1.033492, Train Error: 0.139474, Test Error: 0.159789\n",
      "Epoch: 64, Train Loss: 1.033303, Train Error: 0.139004, Test Error: 0.159632\n",
      "Epoch: 65, Train Loss: 1.033116, Train Error: 0.138541, Test Error: 0.159485\n",
      "Epoch: 66, Train Loss: 1.032923, Train Error: 0.138039, Test Error: 0.159334\n",
      "Epoch: 67, Train Loss: 1.032779, Train Error: 0.137688, Test Error: 0.159163\n",
      "Epoch: 68, Train Loss: 1.032586, Train Error: 0.137207, Test Error: 0.159002\n",
      "Epoch: 69, Train Loss: 1.032438, Train Error: 0.136851, Test Error: 0.158834\n",
      "Epoch: 70, Train Loss: 1.032282, Train Error: 0.136466, Test Error: 0.158699\n",
      "Epoch: 71, Train Loss: 1.032138, Train Error: 0.136123, Test Error: 0.158541\n",
      "Epoch: 72, Train Loss: 1.031993, Train Error: 0.135766, Test Error: 0.158428\n",
      "Epoch: 73, Train Loss: 1.031850, Train Error: 0.135428, Test Error: 0.158279\n",
      "Epoch: 74, Train Loss: 1.031718, Train Error: 0.135112, Test Error: 0.158155\n",
      "Epoch: 75, Train Loss: 1.031574, Train Error: 0.134761, Test Error: 0.158062\n",
      "Epoch: 76, Train Loss: 1.031486, Train Error: 0.134553, Test Error: 0.158065\n",
      "Epoch: 77, Train Loss: 1.031336, Train Error: 0.134182, Test Error: 0.157958\n",
      "Epoch: 78, Train Loss: 1.031224, Train Error: 0.133920, Test Error: 0.157948\n",
      "Epoch: 79, Train Loss: 1.031096, Train Error: 0.133609, Test Error: 0.157836\n",
      "Epoch: 80, Train Loss: 1.031014, Train Error: 0.133430, Test Error: 0.157838\n",
      "Epoch: 81, Train Loss: 1.030911, Train Error: 0.133186, Test Error: 0.157757\n",
      "Epoch: 82, Train Loss: 1.030831, Train Error: 0.133007, Test Error: 0.157759\n",
      "Epoch: 83, Train Loss: 1.030724, Train Error: 0.132777, Test Error: 0.157673\n",
      "Epoch: 84, Train Loss: 1.030632, Train Error: 0.132558, Test Error: 0.157561\n",
      "Epoch: 85, Train Loss: 1.030506, Train Error: 0.132271, Test Error: 0.157445\n",
      "Epoch: 86, Train Loss: 1.030432, Train Error: 0.132103, Test Error: 0.157386\n",
      "Epoch: 87, Train Loss: 1.030361, Train Error: 0.131951, Test Error: 0.157310\n",
      "Epoch: 88, Train Loss: 1.030313, Train Error: 0.131826, Test Error: 0.157247\n",
      "Epoch: 89, Train Loss: 1.030221, Train Error: 0.131622, Test Error: 0.157117\n",
      "Epoch: 90, Train Loss: 1.030118, Train Error: 0.131353, Test Error: 0.157108\n",
      "Epoch: 91, Train Loss: 1.030031, Train Error: 0.131159, Test Error: 0.157000\n",
      "Epoch: 92, Train Loss: 1.029941, Train Error: 0.130920, Test Error: 0.156994\n",
      "Epoch: 93, Train Loss: 1.029862, Train Error: 0.130749, Test Error: 0.156954\n",
      "Epoch: 94, Train Loss: 1.029800, Train Error: 0.130574, Test Error: 0.156884\n",
      "Epoch: 95, Train Loss: 1.029705, Train Error: 0.130371, Test Error: 0.156779\n",
      "Epoch: 96, Train Loss: 1.029618, Train Error: 0.130150, Test Error: 0.156738\n",
      "Epoch: 97, Train Loss: 1.029532, Train Error: 0.129987, Test Error: 0.156693\n",
      "Epoch: 98, Train Loss: 1.029447, Train Error: 0.129793, Test Error: 0.156817\n",
      "Epoch: 99, Train Loss: 1.029379, Train Error: 0.129675, Test Error: 0.156815\n",
      "Epoch: 100, Train Loss: 1.029297, Train Error: 0.129485, Test Error: 0.156829\n",
      "Val Error: 0.156723\n",
      "----- Fold 3 -----\n",
      "Epoch: 0, Train Loss: 1.100159, Train Error: 0.231337, Test Error: 0.202915\n",
      "Epoch: 1, Train Loss: 1.070146, Train Error: 0.200300, Test Error: 0.192498\n",
      "Epoch: 2, Train Loss: 1.064768, Train Error: 0.193974, Test Error: 0.188597\n",
      "Epoch: 3, Train Loss: 1.062180, Train Error: 0.191079, Test Error: 0.186451\n",
      "Epoch: 4, Train Loss: 1.060459, Train Error: 0.189164, Test Error: 0.185263\n",
      "Epoch: 5, Train Loss: 1.059130, Train Error: 0.187582, Test Error: 0.182267\n",
      "Epoch: 6, Train Loss: 1.055739, Train Error: 0.182963, Test Error: 0.179379\n",
      "Epoch: 7, Train Loss: 1.055094, Train Error: 0.182104, Test Error: 0.179025\n",
      "Epoch: 8, Train Loss: 1.054801, Train Error: 0.181698, Test Error: 0.178605\n",
      "Epoch: 9, Train Loss: 1.054526, Train Error: 0.181282, Test Error: 0.178233\n",
      "Epoch: 10, Train Loss: 1.054229, Train Error: 0.180819, Test Error: 0.177947\n",
      "Epoch: 11, Train Loss: 1.053959, Train Error: 0.180431, Test Error: 0.177688\n",
      "Epoch: 12, Train Loss: 1.053742, Train Error: 0.180133, Test Error: 0.177504\n",
      "Epoch: 13, Train Loss: 1.053542, Train Error: 0.179835, Test Error: 0.177312\n",
      "Epoch: 14, Train Loss: 1.053354, Train Error: 0.179544, Test Error: 0.177129\n",
      "Epoch: 15, Train Loss: 1.053182, Train Error: 0.179272, Test Error: 0.177007\n",
      "Epoch: 16, Train Loss: 1.053009, Train Error: 0.178995, Test Error: 0.176896\n",
      "Epoch: 17, Train Loss: 1.052844, Train Error: 0.178729, Test Error: 0.176796\n",
      "Epoch: 18, Train Loss: 1.052666, Train Error: 0.178456, Test Error: 0.176765\n",
      "Epoch: 19, Train Loss: 1.052480, Train Error: 0.178151, Test Error: 0.176646\n",
      "Epoch: 20, Train Loss: 1.052292, Train Error: 0.177840, Test Error: 0.176586\n",
      "Epoch: 21, Train Loss: 1.052058, Train Error: 0.177442, Test Error: 0.176389\n",
      "Epoch: 22, Train Loss: 1.051805, Train Error: 0.177042, Test Error: 0.176283\n",
      "Epoch: 23, Train Loss: 1.051550, Train Error: 0.176610, Test Error: 0.176152\n",
      "Epoch: 24, Train Loss: 1.051314, Train Error: 0.176197, Test Error: 0.176093\n",
      "Epoch: 25, Train Loss: 1.051069, Train Error: 0.175741, Test Error: 0.176004\n",
      "Epoch: 26, Train Loss: 1.050790, Train Error: 0.175208, Test Error: 0.175927\n",
      "Epoch: 27, Train Loss: 1.050534, Train Error: 0.174695, Test Error: 0.175800\n",
      "Epoch: 28, Train Loss: 1.050273, Train Error: 0.174141, Test Error: 0.175597\n",
      "Epoch: 29, Train Loss: 1.050056, Train Error: 0.173654, Test Error: 0.175368\n",
      "Epoch: 30, Train Loss: 1.049748, Train Error: 0.173035, Test Error: 0.175073\n",
      "Epoch: 31, Train Loss: 1.049459, Train Error: 0.172406, Test Error: 0.174675\n",
      "Epoch: 32, Train Loss: 1.049144, Train Error: 0.171723, Test Error: 0.174280\n",
      "Epoch: 33, Train Loss: 1.048793, Train Error: 0.170957, Test Error: 0.173946\n",
      "Epoch: 34, Train Loss: 1.048442, Train Error: 0.170192, Test Error: 0.173682\n",
      "Epoch: 35, Train Loss: 1.048074, Train Error: 0.169407, Test Error: 0.173271\n",
      "Epoch: 36, Train Loss: 1.047710, Train Error: 0.168605, Test Error: 0.172727\n",
      "Epoch: 37, Train Loss: 1.047357, Train Error: 0.167841, Test Error: 0.172111\n",
      "Epoch: 38, Train Loss: 1.046974, Train Error: 0.167015, Test Error: 0.171418\n",
      "Epoch: 39, Train Loss: 1.046593, Train Error: 0.166202, Test Error: 0.170779\n",
      "Epoch: 40, Train Loss: 1.046190, Train Error: 0.165335, Test Error: 0.170131\n",
      "Epoch: 41, Train Loss: 1.045844, Train Error: 0.164543, Test Error: 0.169597\n",
      "Epoch: 42, Train Loss: 1.045490, Train Error: 0.163767, Test Error: 0.168957\n",
      "Epoch: 43, Train Loss: 1.045033, Train Error: 0.162728, Test Error: 0.168345\n",
      "Epoch: 44, Train Loss: 1.044572, Train Error: 0.161729, Test Error: 0.167675\n",
      "Epoch: 45, Train Loss: 1.044177, Train Error: 0.160920, Test Error: 0.167051\n",
      "Epoch: 46, Train Loss: 1.043697, Train Error: 0.159903, Test Error: 0.166310\n",
      "Epoch: 47, Train Loss: 1.043255, Train Error: 0.158955, Test Error: 0.165643\n",
      "Epoch: 48, Train Loss: 1.042860, Train Error: 0.158092, Test Error: 0.164978\n",
      "Epoch: 49, Train Loss: 1.042402, Train Error: 0.157210, Test Error: 0.164232\n",
      "Epoch: 50, Train Loss: 1.042035, Train Error: 0.156444, Test Error: 0.163565\n",
      "Epoch: 51, Train Loss: 1.041722, Train Error: 0.155912, Test Error: 0.163069\n",
      "Epoch: 52, Train Loss: 1.041288, Train Error: 0.155094, Test Error: 0.162336\n",
      "Epoch: 53, Train Loss: 1.040772, Train Error: 0.154060, Test Error: 0.161650\n",
      "Epoch: 54, Train Loss: 1.040329, Train Error: 0.153199, Test Error: 0.161048\n",
      "Epoch: 55, Train Loss: 1.039865, Train Error: 0.152339, Test Error: 0.160479\n",
      "Epoch: 56, Train Loss: 1.039445, Train Error: 0.151622, Test Error: 0.159767\n",
      "Epoch: 57, Train Loss: 1.038968, Train Error: 0.150746, Test Error: 0.159189\n",
      "Epoch: 58, Train Loss: 1.038557, Train Error: 0.150057, Test Error: 0.158619\n",
      "Epoch: 59, Train Loss: 1.038111, Train Error: 0.149280, Test Error: 0.158033\n",
      "Epoch: 60, Train Loss: 1.037690, Train Error: 0.148591, Test Error: 0.157573\n",
      "Epoch: 61, Train Loss: 1.037240, Train Error: 0.147769, Test Error: 0.157109\n",
      "Epoch: 62, Train Loss: 1.036900, Train Error: 0.147227, Test Error: 0.156619\n",
      "Epoch: 63, Train Loss: 1.036450, Train Error: 0.146434, Test Error: 0.155956\n",
      "Epoch: 64, Train Loss: 1.036033, Train Error: 0.145693, Test Error: 0.155456\n",
      "Epoch: 65, Train Loss: 1.035606, Train Error: 0.144942, Test Error: 0.154927\n",
      "Epoch: 66, Train Loss: 1.035256, Train Error: 0.144356, Test Error: 0.154495\n",
      "Epoch: 67, Train Loss: 1.034860, Train Error: 0.143659, Test Error: 0.154055\n",
      "Epoch: 68, Train Loss: 1.034546, Train Error: 0.143111, Test Error: 0.153771\n",
      "Epoch: 69, Train Loss: 1.034230, Train Error: 0.142550, Test Error: 0.153397\n",
      "Epoch: 70, Train Loss: 1.033969, Train Error: 0.142072, Test Error: 0.153223\n",
      "Epoch: 71, Train Loss: 1.033712, Train Error: 0.141599, Test Error: 0.152931\n",
      "Epoch: 72, Train Loss: 1.033559, Train Error: 0.141330, Test Error: 0.152724\n",
      "Epoch: 73, Train Loss: 1.033309, Train Error: 0.140804, Test Error: 0.152506\n",
      "Epoch: 74, Train Loss: 1.033124, Train Error: 0.140418, Test Error: 0.152357\n",
      "Epoch: 75, Train Loss: 1.032969, Train Error: 0.140107, Test Error: 0.152255\n",
      "Epoch: 76, Train Loss: 1.032831, Train Error: 0.139836, Test Error: 0.152149\n",
      "Epoch: 77, Train Loss: 1.032657, Train Error: 0.139460, Test Error: 0.152103\n",
      "Epoch: 78, Train Loss: 1.032518, Train Error: 0.139162, Test Error: 0.151947\n",
      "Epoch: 79, Train Loss: 1.032364, Train Error: 0.138804, Test Error: 0.151812\n",
      "Epoch: 80, Train Loss: 1.032253, Train Error: 0.138568, Test Error: 0.151769\n",
      "Epoch: 81, Train Loss: 1.032171, Train Error: 0.138401, Test Error: 0.151738\n",
      "Epoch: 82, Train Loss: 1.032038, Train Error: 0.138090, Test Error: 0.151659\n",
      "Epoch: 83, Train Loss: 1.031904, Train Error: 0.137784, Test Error: 0.151635\n",
      "Epoch: 84, Train Loss: 1.031790, Train Error: 0.137535, Test Error: 0.151594\n",
      "Epoch: 85, Train Loss: 1.031671, Train Error: 0.137260, Test Error: 0.151531\n",
      "Epoch: 86, Train Loss: 1.031551, Train Error: 0.136994, Test Error: 0.151414\n",
      "Epoch: 87, Train Loss: 1.031448, Train Error: 0.136749, Test Error: 0.151395\n",
      "Epoch: 88, Train Loss: 1.031323, Train Error: 0.136462, Test Error: 0.151307\n",
      "Epoch: 89, Train Loss: 1.031219, Train Error: 0.136199, Test Error: 0.151163\n",
      "Epoch: 90, Train Loss: 1.031116, Train Error: 0.135965, Test Error: 0.151045\n",
      "Epoch: 91, Train Loss: 1.031027, Train Error: 0.135771, Test Error: 0.151053\n",
      "Epoch: 92, Train Loss: 1.030910, Train Error: 0.135519, Test Error: 0.151064\n",
      "Epoch: 93, Train Loss: 1.030807, Train Error: 0.135283, Test Error: 0.150947\n",
      "Epoch: 94, Train Loss: 1.030687, Train Error: 0.135026, Test Error: 0.150931\n",
      "Epoch: 95, Train Loss: 1.030599, Train Error: 0.134835, Test Error: 0.150916\n",
      "Epoch: 96, Train Loss: 1.030473, Train Error: 0.134561, Test Error: 0.150896\n",
      "Epoch: 97, Train Loss: 1.030404, Train Error: 0.134423, Test Error: 0.150870\n",
      "Epoch: 98, Train Loss: 1.030284, Train Error: 0.134172, Test Error: 0.150824\n",
      "Epoch: 99, Train Loss: 1.030191, Train Error: 0.133958, Test Error: 0.150790\n",
      "Epoch: 100, Train Loss: 1.030101, Train Error: 0.133773, Test Error: 0.150888\n",
      "Epoch: 101, Train Loss: 1.030012, Train Error: 0.133556, Test Error: 0.150833\n",
      "Epoch: 102, Train Loss: 1.029940, Train Error: 0.133390, Test Error: 0.150681\n",
      "Epoch: 103, Train Loss: 1.029833, Train Error: 0.133119, Test Error: 0.150612\n",
      "Epoch: 104, Train Loss: 1.029750, Train Error: 0.132924, Test Error: 0.150622\n",
      "Epoch: 105, Train Loss: 1.029683, Train Error: 0.132747, Test Error: 0.150602\n",
      "Epoch: 106, Train Loss: 1.029617, Train Error: 0.132595, Test Error: 0.150605\n",
      "Epoch: 107, Train Loss: 1.029542, Train Error: 0.132407, Test Error: 0.150582\n",
      "Epoch: 108, Train Loss: 1.029461, Train Error: 0.132205, Test Error: 0.150573\n",
      "Epoch: 109, Train Loss: 1.029388, Train Error: 0.131992, Test Error: 0.150597\n",
      "Epoch: 110, Train Loss: 1.029310, Train Error: 0.131781, Test Error: 0.150598\n",
      "Epoch: 111, Train Loss: 1.029237, Train Error: 0.131596, Test Error: 0.150652\n",
      "Val Error: 0.150688\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=args.splits, random_state=42, shuffle=True)\n",
    "\n",
    "ks = [0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "\n",
    "best_model_fold_list = []\n",
    "data_fold_list = []\n",
    "i = 1\n",
    "for train_index, test_index in cv.split(X):\n",
    "\n",
    "    print(f\"----- Fold {i} -----\")\n",
    "\n",
    "    model = GSRNet(ks, args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = X[\n",
    "        train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "    data_fold_list.append((subjects_adj, test_adj, subjects_ground_truth, test_ground_truth))\n",
    "\n",
    "\n",
    "    ##################\n",
    "    # subjects_adj = subjects_adj[:1]\n",
    "    # subjects_ground_truth = subjects_ground_truth[:1]\n",
    "    ##################\n",
    "\n",
    "    return_model = train(model, optimizer, subjects_adj, subjects_ground_truth, args, test_adj, test_ground_truth)\n",
    "    test(return_model, test_adj, test_ground_truth, args)\n",
    "    best_model_fold_list.append(return_model)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixVectorizer import MatrixVectorizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "def evaluate(pred_matrices, gt_matrices):\n",
    "\n",
    "    num_test_samples = gt_matrices.shape[0]\n",
    "\n",
    "    # Initialize lists to store MAEs for each centrality measure\n",
    "    mae_bc = []\n",
    "    mae_ec = []\n",
    "    mae_pc = []\n",
    "\n",
    "    # # Iterate over each test sample\n",
    "    # for i in range(num_test_samples):\n",
    "    #     # Convert adjacency matrices to NetworkX graphs\n",
    "    #     pred_graph = nx.from_numpy_array(pred_matrices[i], edge_attr=\"weight\")\n",
    "    #     gt_graph = nx.from_numpy_array(gt_matrices[i], edge_attr=\"weight\")\n",
    "\n",
    "    #     # Compute centrality measures\n",
    "    #     pred_bc = nx.betweenness_centrality(pred_graph, weight=\"weight\")\n",
    "    #     pred_ec = nx.eigenvector_centrality(pred_graph, weight=\"weight\")\n",
    "    #     pred_pc = nx.pagerank(pred_graph, weight=\"weight\")\n",
    "\n",
    "    #     gt_bc = nx.betweenness_centrality(gt_graph, weight=\"weight\")\n",
    "    #     gt_ec = nx.eigenvector_centrality(gt_graph, weight=\"weight\")\n",
    "    #     gt_pc = nx.pagerank(gt_graph, weight=\"weight\")\n",
    "\n",
    "    #     # Convert centrality dictionaries to lists\n",
    "    #     pred_bc_values = list(pred_bc.values())\n",
    "    #     pred_ec_values = list(pred_ec.values())\n",
    "    #     pred_pc_values = list(pred_pc.values())\n",
    "\n",
    "    #     gt_bc_values = list(gt_bc.values())\n",
    "    #     gt_ec_values = list(gt_ec.values())\n",
    "    #     gt_pc_values = list(gt_pc.values())\n",
    "\n",
    "    #     # Compute MAEs\n",
    "    #     mae_bc.append(mean_absolute_error(pred_bc_values, gt_bc_values))\n",
    "    #     mae_ec.append(mean_absolute_error(pred_ec_values, gt_ec_values))\n",
    "    #     mae_pc.append(mean_absolute_error(pred_pc_values, gt_pc_values))\n",
    "\n",
    "    # # Compute average MAEs\n",
    "    # avg_mae_bc = sum(mae_bc) / len(mae_bc)\n",
    "    # avg_mae_ec = sum(mae_ec) / len(mae_ec)\n",
    "    # avg_mae_pc = sum(mae_pc) / len(mae_pc)\n",
    "\n",
    "    # vectorize and flatten\n",
    "    pred_1d = MatrixVectorizer.vectorize(pred_matrices).flatten()\n",
    "    gt_1d = MatrixVectorizer.vectorize(gt_matrices).flatten()\n",
    "\n",
    "    mae = mean_absolute_error(pred_1d, gt_1d)\n",
    "    pcc = pearsonr(pred_1d, gt_1d)[0]\n",
    "    js_dis = jensenshannon(pred_1d, gt_1d)\n",
    "\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"PCC: \", pcc)\n",
    "    print(\"Jensen-Shannon Distance: \", js_dis)\n",
    "    # print(\"Average MAE betweenness centrality:\", avg_mae_bc)\n",
    "    # print(\"Average MAE eigenvector centrality:\", avg_mae_ec)\n",
    "    # print(\"Average MAE PageRank centrality:\", avg_mae_pc)\n",
    "    # return mae, pcc, js_dis, avg_mae_bc, avg_mae_ec, avg_mae_pc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.15258984861700553\n",
      "PCC:  0.5647187281965296\n",
      "Jensen-Shannon Distance:  0.3051966685634413\n",
      "MAE:  0.15993713084613775\n",
      "PCC:  0.5497364610358499\n",
      "Jensen-Shannon Distance:  0.3108364436599916\n",
      "MAE:  0.15587243734885348\n",
      "PCC:  0.5627382446718319\n",
      "Jensen-Shannon Distance:  0.2989439438571562\n"
     ]
    }
   ],
   "source": [
    "for i in range(args.splits):\n",
    "    _, test_adjs, _, gt_matrices = data_fold_list[i]\n",
    "    model = best_model_fold_list[i]\n",
    "    model.eval()\n",
    "    pred_matrices = np.zeros(gt_matrices.shape)\n",
    "    with torch.no_grad():\n",
    "        for j, test_adj in enumerate(test_adjs):\n",
    "            pred_matrices[j], _, _, _ = model(torch.from_numpy(test_adj))\n",
    "    evaluate(pred_matrices, gt_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.epochs = 90\n",
    "\n",
    "# final_model = GSRNet(ks, args).to(device)\n",
    "# optimizer = optim.Adam(final_model.parameters(), lr=args.lr)\n",
    "\n",
    "# # subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = X[\n",
    "# #     train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "# # data_fold_list.append((subjects_adj, test_adj, subjects_ground_truth, test_ground_truth))\n",
    "\n",
    "\n",
    "# ##################\n",
    "# # subjects_adj = subjects_adj[:1]\n",
    "# # subjects_ground_truth = subjects_ground_truth[:1]\n",
    "# ##################\n",
    "\n",
    "# final_model = train(final_model, optimizer, X, Y, args)\n",
    "\n",
    "final_model = best_model_fold_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_list = []\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(A_LR_test_matrix.shape[0]):\n",
    "        output_pred, _, _, _ = final_model(torch.Tensor(A_LR_test_matrix[i]))\n",
    "        output_pred = MatrixVectorizer.vectorize(output_pred).tolist()\n",
    "        output_pred_list.append(output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pred_stack = np.stack(output_pred_list, axis=0)\n",
    "output_pred_1d = output_pred_stack.flatten()\n",
    "assert output_pred_1d.shape == (4007136, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.520644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.637607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.521840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.605539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.435210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007131</th>\n",
       "      <td>4007132</td>\n",
       "      <td>0.133885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007132</th>\n",
       "      <td>4007133</td>\n",
       "      <td>0.084706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007133</th>\n",
       "      <td>4007134</td>\n",
       "      <td>0.134227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007134</th>\n",
       "      <td>4007135</td>\n",
       "      <td>0.044320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007135</th>\n",
       "      <td>4007136</td>\n",
       "      <td>0.042881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4007136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  Predicted\n",
       "0              1   0.520644\n",
       "1              2   0.637607\n",
       "2              3   0.521840\n",
       "3              4   0.605539\n",
       "4              5   0.435210\n",
       "...          ...        ...\n",
       "4007131  4007132   0.133885\n",
       "4007132  4007133   0.084706\n",
       "4007133  4007134   0.134227\n",
       "4007134  4007135   0.044320\n",
       "4007135  4007136   0.042881\n",
       "\n",
       "[4007136 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"ID\": [i+1 for i in range(len(output_pred_1d))],\n",
    "    \"Predicted\": output_pred_1d.tolist()\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
