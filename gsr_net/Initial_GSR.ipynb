{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MatrixVectorizer import MatrixVectorizer\n",
    "from preprocessing import antivectorize_df\n",
    "from model import GSRNet, Discriminator\n",
    "from train import train_gan, test_gan\n",
    "from utils import track_memory, compute_degree_matrix_normalization_batch_numpy, get_parser, evaluate, plot_metrics_fold, LR_size, HR_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Check for CUDA (GPU support) and set device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # For multi-GPU setups\n",
    "    # Additional settings for ensuring reproducibility on CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_LR_train = pd.read_csv(\"../data/lr_train.csv\")\n",
    "# A_HR_train = pd.read_csv(\"../data/hr_train.csv\")\n",
    "# A_LR_test = pd.read_csv(\"../data/lr_test.csv\")\n",
    "\n",
    "# np.save('A_LR_train_matrix.npy', antivectorize_df(A_LR_train, LR_size))\n",
    "# np.save('A_HR_train_matrix.npy', antivectorize_df(A_HR_train, HR_size))\n",
    "# np.save('A_LR_test_matrix.npy', antivectorize_df(A_LR_test, LR_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_LR_train_matrix = np.load('A_LR_train_matrix.npy')\n",
    "A_HR_train_matrix = np.load('A_HR_train_matrix.npy')\n",
    "A_LR_test_matrix = np.load(\"A_LR_test_matrix.npy\")\n",
    "\n",
    "print(A_LR_train_matrix.shape)\n",
    "print(A_HR_train_matrix.shape)\n",
    "print(A_LR_test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "# Create an empty Namespace to hold the default arguments\n",
    "args = parser.parse_args([])\n",
    "pprint(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATING THE DATA: EDIT TO ENTER YOUR OWN DATA\n",
    "X = A_LR_train_matrix  # np.random.normal(0, 0.5, (167, 160, 160))\n",
    "Y = A_HR_train_matrix  # np.random.normal(0, 0.5, (167, 288, 288))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = compute_degree_matrix_normalization_batch_numpy(X)\n",
    "A_LR_test_matrix = compute_degree_matrix_normalization_batch_numpy(A_LR_test_matrix)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=args.splits, random_state=random_seed, shuffle=True)\n",
    "\n",
    "best_model_fold_list = []\n",
    "data_fold_list = []\n",
    "i = 1\n",
    "for train_index, test_index in cv.split(X):\n",
    "\n",
    "    print(f\"----- Fold {i} -----\")\n",
    "\n",
    "    subjects_adj, test_adj, subjects_ground_truth, test_ground_truth = (\n",
    "        X[train_index],\n",
    "        X[test_index],\n",
    "        Y[train_index],\n",
    "        Y[test_index],\n",
    "    )\n",
    "    data_fold_list.append(\n",
    "        (subjects_adj, test_adj, subjects_ground_truth, test_ground_truth)\n",
    "    )\n",
    "\n",
    "    netG = GSRNet(args).to(device)\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=args.lr)\n",
    "\n",
    "    netD = Discriminator(args).to(device)\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=args.lr)\n",
    "\n",
    "    track_memory()\n",
    "    # GAN model\n",
    "    return_model = train_gan(\n",
    "        netG,\n",
    "        optimizerG,\n",
    "        netD,\n",
    "        optimizerD,\n",
    "        subjects_adj,\n",
    "        subjects_ground_truth,\n",
    "        args,\n",
    "        test_adj=test_adj,\n",
    "        test_ground_truth=test_ground_truth,\n",
    "    )\n",
    "    track_memory()\n",
    "\n",
    "    test_mae = test_gan(return_model, test_adj, test_ground_truth, args)\n",
    "    train_mae = test_gan(return_model, subjects_adj, subjects_ground_truth, args)\n",
    "    print(f\"Train MAE: {train_mae:.6f}, Val MAE: {test_mae:.6f}\")\n",
    "    best_model_fold_list.append(return_model)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_GRAPH = False\n",
    "\n",
    "res_list = []\n",
    "\n",
    "for i in range(args.splits):\n",
    "    _, test_adjs, _, gt_matrices = data_fold_list[i]\n",
    "    model = best_model_fold_list[i]\n",
    "    model.eval()\n",
    "    pred_matrices = np.zeros(gt_matrices.shape)\n",
    "    with torch.no_grad():\n",
    "        for j, test_adj in enumerate(test_adjs):\n",
    "            pred = model(torch.from_numpy(test_adj))[0]\n",
    "            pred = torch.clamp(pred, min=0.0, max=1.0)\n",
    "            pred = pred.cpu()\n",
    "            pred_matrices[j] = pred\n",
    "    res_list.append(evaluate(pred_matrices, gt_matrices, cal_graph=CAL_GRAPH))\n",
    "\n",
    "pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_fold(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.splits):\n",
    "    _, test_adjs, _, gt_matrices = data_fold_list[i]\n",
    "    model = best_model_fold_list[i]\n",
    "    model.eval()\n",
    "\n",
    "    output_pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for test_adj in tqdm(test_adjs):\n",
    "            output_pred = model(torch.from_numpy(test_adj))[0].cpu()\n",
    "            output_pred = MatrixVectorizer.vectorize(output_pred).tolist()\n",
    "            output_pred_list.append(output_pred)\n",
    "\n",
    "    output_pred_stack = np.stack(output_pred_list, axis=0)\n",
    "    output_pred_1d = output_pred_stack.flatten()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"ID\": [i + 1 for i in range(len(output_pred_1d))],\n",
    "            \"Predicted\": output_pred_1d.tolist(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df.to_csv(\"predictions_fold_\" + str(i + 1) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_HR_train = pd.read_csv(\"../data/hr_train.csv\")\n",
    "\n",
    "pca = PCA(n_components=0.99, whiten=False)\n",
    "A_HR_train_pca = pca.fit_transform(A_HR_train)\n",
    "print(f\"HR Train PCA shape: {A_HR_train_pca.shape}\")\n",
    "\n",
    "gm = GaussianMixture(n_components=5, random_state=random_seed)\n",
    "A_HR_train_label = gm.fit_predict(A_HR_train_pca)\n",
    "unique, counts = np.unique(A_HR_train_label, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "X = np.load(\"A_LR_train_matrix.npy\")\n",
    "y = np.load(\"A_HR_train_matrix.npy\")\n",
    "\n",
    "X = compute_degree_matrix_normalization_batch_numpy(X)\n",
    "\n",
    "n_sample = X.shape[0]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X.reshape(n_sample, -1),\n",
    "    y.reshape(n_sample, -1),\n",
    "    test_size=0.10,\n",
    "    random_state=random_seed,\n",
    "    stratify=A_HR_train_label,\n",
    ")\n",
    "\n",
    "X_train = X_train.reshape(-1, LR_size, LR_size)\n",
    "X_val = X_val.reshape(-1, LR_size, LR_size)\n",
    "y_train = y_train.reshape(-1, HR_size, HR_size)\n",
    "y_val = y_val.reshape(-1, HR_size, HR_size)\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Val size:\", len(X_val))\n",
    "\n",
    "netG = GSRNet(args).to(device)\n",
    "print(\"here\")\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=args.lr)\n",
    "\n",
    "print(\"here\")\n",
    "netD = Discriminator(args).to(device)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=args.lr)\n",
    "print(\"here\")\n",
    "\n",
    "track_memory()\n",
    "# GAN model\n",
    "final_model = train_gan(\n",
    "    netG,\n",
    "    optimizerG,\n",
    "    netD,\n",
    "    optimizerD,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    args,\n",
    "    test_adj=X_val,\n",
    "    test_ground_truth=y_val,\n",
    ")\n",
    "track_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.eval()\n",
    "pred_train_matrices = np.zeros(y_train.shape)\n",
    "pred_val_matrices = np.zeros(y_val.shape)\n",
    "with torch.no_grad():\n",
    "    for j, test_adj in enumerate(X_train):\n",
    "        pred = final_model(torch.from_numpy(test_adj))[0]\n",
    "        pred = torch.clamp(pred, min=0.0, max=1.0)\n",
    "        pred = pred.cpu()\n",
    "        pred_train_matrices[j] = pred\n",
    "\n",
    "    print(\"Train\")\n",
    "    evaluate(pred_train_matrices, y_train)\n",
    "\n",
    "    for j, test_adj in enumerate(X_val):\n",
    "        pred = final_model(torch.from_numpy(test_adj))[0]\n",
    "        pred = torch.clamp(pred, min=0.0, max=1.0)\n",
    "        pred = pred.cpu()\n",
    "        pred_val_matrices[j] = pred\n",
    "\n",
    "    print(\"Val\")\n",
    "    evaluate(pred_val_matrices, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_list = []\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(A_LR_test_matrix.shape[0])):\n",
    "        output_pred = final_model(torch.Tensor(A_LR_test_matrix[i]))[0]\n",
    "        output_pred = torch.clamp(output_pred, min=0.0, max=1.0)\n",
    "        output_pred = output_pred.cpu()\n",
    "        output_pred = MatrixVectorizer.vectorize(output_pred).tolist()\n",
    "        output_pred_list.append(output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_stack = np.stack(output_pred_list, axis=0)\n",
    "output_pred_1d = output_pred_stack.flatten()\n",
    "assert output_pred_1d.shape == (4007136,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": [i + 1 for i in range(len(output_pred_1d))],\n",
    "        \"Predicted\": output_pred_1d.tolist(),\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_model.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
